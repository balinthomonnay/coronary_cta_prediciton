{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from functools import partial, update_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are GPU options, that were required for my computing device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Flatten, Dense, concatenate, Conv2D, Conv3D, MaxPooling2D, MaxPooling3D, Conv2DTranspose, Conv3DTranspose\n",
    "from keras.layers import Activation, add, multiply, Lambda\n",
    "from keras.layers import AveragePooling2D, AveragePooling3D, average, UpSampling2D, UpSampling3D, Dropout\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.initializers import glorot_normal, random_normal, random_uniform\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapped_partial(func, *args, **kwargs):\n",
    "    partial_func = partial(func, *args, **kwargs)\n",
    "    update_wrapper(partial_func, func)\n",
    "    return partial_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsc(y_true, y_pred, args):\n",
    "    smooth = args.smooth\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred, args):\n",
    "    loss = 1 - dsc(y_true, y_pred, args)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def tp(y_true, y_pred, args):\n",
    "    smooth = args.smooth\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    tp = (K.sum(y_pos * y_pred_pos) + smooth) / (K.sum(y_pos) + smooth)\n",
    "    return tp\n",
    "\n",
    "\n",
    "def tn(y_true, y_pred, args):\n",
    "    smooth = args.smooth\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "    tn = (K.sum(y_neg * y_pred_neg) + smooth) / (K.sum(y_neg) + smooth)\n",
    "    return tn\n",
    "\n",
    "\n",
    "def fp(y_true, y_pred, args):\n",
    "    smooth = args.smooth\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "    fp = (K.sum(y_neg * y_pred_pos) + smooth) / (K.sum(y_pred) + smooth)\n",
    "    return fp\n",
    "\n",
    "\n",
    "def fn(y_true, y_pred, args):\n",
    "    smooth = args.smooth\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "    fn = (K.sum(y_pos * y_pred_neg) + smooth) / (K.sum(y_pred_neg) + smooth)\n",
    "    return fn\n",
    "\n",
    "\n",
    "def multiloss(y_true, y_pred, args):\n",
    "    if args.loss_type == 1:\n",
    "        return focal_tversky(y_true, y_pred, args)\n",
    "    else:\n",
    "        return dice_loss(y_true, y_pred, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_as_3d(tensor, rep, name):\n",
    "    my_repeat = Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=4), arguments={'repnum': rep},\n",
    "                       name='psi_up' + name)(tensor)\n",
    "    return my_repeat\n",
    "\n",
    "\n",
    "def AttnGatingBlock3D(x, g, inter_shape, name):\n",
    "    '''\n",
    "    Analogous implementation of the 3D attention gate used in the Attention U-Net 3D.\n",
    "    '''\n",
    "    shape_x = K.int_shape(x)  # 32\n",
    "    shape_g = K.int_shape(g)  # 16\n",
    "\n",
    "    theta_x = Conv3D(inter_shape, (2, 2, 2), strides=(2, 2, 2), padding='same', name='xl' + name)(x)  # 16\n",
    "    shape_theta_x = K.int_shape(theta_x)\n",
    "\n",
    "    phi_g = Conv3D(inter_shape, (1, 1, 1), padding='same')(g)\n",
    "    upsample_g = Conv3DTranspose(inter_shape, (3, 3, 3), strides=(\n",
    "    shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2], shape_theta_x[3] // shape_g[3]), padding='same',\n",
    "                                 name='g_up' + name)(phi_g)  # 16\n",
    "\n",
    "    concat_xg = add([upsample_g, theta_x])\n",
    "    act_xg = Activation('relu')(concat_xg)\n",
    "    psi = Conv3D(1, (1, 1, 1), padding='same', name='psi' + name)(act_xg)\n",
    "    sigmoid_xg = Activation('sigmoid')(psi)\n",
    "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
    "    upsample_psi = UpSampling3D(\n",
    "        size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2], shape_x[3] // shape_sigmoid[3]))(\n",
    "        sigmoid_xg)  # 32\n",
    "\n",
    "    upsample_psi = expand_as_3d(upsample_psi, shape_x[4], name)\n",
    "    y = multiply([upsample_psi, x], name='q_attn' + name)\n",
    "\n",
    "    result = Conv3D(shape_x[4], (1, 1, 1), padding='same', name='q_attn_conv' + name)(y)\n",
    "    result_bn = BatchNormalization(name='q_attn_bn' + name)(result)\n",
    "    return result_bn\n",
    "\n",
    "\n",
    "def UnetConv3D(input, outdim, is_batchnorm, name):\n",
    "    '''\n",
    "    Analogous implementation of the pair of convolutional layers used by the U-Net 3D.\n",
    "    '''\n",
    "    x = Conv3D(outdim, (3, 3, 3), strides=(1, 1, 1), kernel_initializer=\"glorot_normal\", padding=\"same\",\n",
    "               name=name + '_1')(input)\n",
    "    if is_batchnorm:\n",
    "        x = BatchNormalization(name=name + '_1_bn')(x)\n",
    "    x = Activation('relu', name=name + '_1_act')(x)\n",
    "\n",
    "    x = Conv3D(outdim, (3, 3, 3), strides=(1, 1, 1), kernel_initializer=\"glorot_normal\", padding=\"same\",\n",
    "               name=name + '_2')(x)\n",
    "    if is_batchnorm:\n",
    "        x = BatchNormalization(name=name + '_2_bn')(x)\n",
    "    x = Activation('relu', name=name + '_2_act')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def UnetGatingSignal3D(input, is_batchnorm, name):\n",
    "    '''\n",
    "    Implementation of the gating signal appearing in the upsampling branch of the Attention U-Net 3D:\n",
    "    simply a 1x1 convolution followed by batch normalization and ReLU.\n",
    "    '''\n",
    "    shape = K.int_shape(input)\n",
    "    x = Conv3D(shape[4] * 1, (1, 1, 1), strides=(1, 1, 1), padding=\"same\", kernel_initializer=\"glorot_normal\",\n",
    "               name=name + '_conv')(input)\n",
    "    if is_batchnorm:\n",
    "        x = BatchNormalization(name=name + '_bn')(x)\n",
    "    x = Activation('relu', name=name + '_act')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def tiny_attn_unet3D(opt, input_size, args):\n",
    "    '''\n",
    "    Analogue of the above defined attn_unet3D with less layers, resulting in a smaller U shape.\n",
    "    '''\n",
    "    inputs = Input(shape=input_size)\n",
    "    conv1 = UnetConv3D(inputs, 8*args.kernel_power, is_batchnorm=True, name='conv1')\n",
    "    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n",
    "    pool1 = Dropout(args.dropout)(pool1)\n",
    "\n",
    "    conv2 = UnetConv3D(pool1, 8*args.kernel_power, is_batchnorm=True, name='conv2')\n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "    pool2 = Dropout(args.dropout)(pool2)\n",
    "\n",
    "    center = UnetConv3D(pool2, 16*args.kernel_power, is_batchnorm=True, name='center')\n",
    "\n",
    "    g3 = UnetGatingSignal3D(center, is_batchnorm=True, name='g3')\n",
    "    attn3 = AttnGatingBlock3D(conv2, g3, 8*args.kernel_power, '_3')\n",
    "    up3 = concatenate([Conv3DTranspose(8*args.kernel_power, (3, 3, 3), strides=(2, 2, 2), padding='same', activation='relu',\n",
    "                                       kernel_initializer=\"glorot_normal\")(center), attn3], name='up3')\n",
    "\n",
    "    up4 = concatenate([Conv3DTranspose(8*args.kernel_power, (3, 3, 3), strides=(2, 2, 2), padding='same', activation='relu',\n",
    "                                       kernel_initializer=\"glorot_normal\")(up3), conv1], name='up4')\n",
    "\n",
    "    mask_1 = Conv3D(1, (1, 1, 1), activation='sigmoid', name='mask_1')(up4)\n",
    "    mask_2 = Conv3D(1, (1, 1, 1), activation='sigmoid', name='mask_2')(up4)\n",
    "    dif = Conv3D(1, (1, 1, 1), activation='sigmoid', name='dif')(up4)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[mask_1, mask_2, dif])\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss=[wrapped_partial(dice_loss, args=args), wrapped_partial(dice_loss, args=args),\n",
    "                        wrapped_partial(multiloss, args=args)],\n",
    "                  loss_weights=[0.1, 0.1, 0.8],\n",
    "                  metrics=[[wrapped_partial(dsc, args=args)], [wrapped_partial(dsc, args=args)],\n",
    "                           [wrapped_partial(dsc, args=args), wrapped_partial(tp, args=args),\n",
    "                            wrapped_partial(tn, args=args)]])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {'alpha': 0.6635482209772863, 'dropout': 0.0022118370088630712, 'gamma': 0.7940638705632237, 'kernel_power': 8, 'learning_rate': 0.00015099469943923109, 'loss_type': 0, 'smooth': 1, 'unet_type': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arg():\n",
    "    def __init__(self):\n",
    "        self.alpha=0.7\n",
    "        self.gamma=0.75\n",
    "        self.loss_type=1 #1 for focal tversky\n",
    "        self.unet_type=0 #1 for attn unet\n",
    "        self.smooth=1\n",
    "        self.learning_rate=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args=arg()\n",
    "args.loss_type=arguments['loss_type']\n",
    "args.unet_type=arguments['unet_type']\n",
    "args.smooth=arguments['smooth']\n",
    "args.alpha=arguments['alpha']\n",
    "args.gamma=arguments['gamma']\n",
    "args.learning_rate=arguments['learning_rate']\n",
    "args.dropout=arguments['dropout']\n",
    "args.kernel_power=arguments['kernel_power']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tiny_attn_unet3D(Adam(learning_rate=args.learning_rate), (24,32,32,1),args)\n",
    "model.load_weights('model_internal_dataset.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_cta_model_evaluation(image, model, z_stride, which_prediction):\n",
    "    '''\n",
    "    Helper function, which given the original ct image of a plaque will give back the masks for the DL segmentation.\n",
    "    '''\n",
    "    # Shape of original images\n",
    "    size_X = image.shape[2]\n",
    "    size_Y = image.shape[1]\n",
    "    size_Z = image.shape[0]\n",
    "\n",
    "    image_paded = np.zeros((size_Z + 24,\n",
    "                            size_Y,\n",
    "                            size_X))\n",
    "\n",
    "    image_paded[:size_Z, :size_Y, :size_X] = image / 512\n",
    "\n",
    "    prediction_array = np.zeros((size_Z + 24,\n",
    "                                 size_Y,\n",
    "                                 size_X))\n",
    "\n",
    "    coverage_array = np.zeros((size_Z + 24,\n",
    "                               size_Y,\n",
    "                               size_X))\n",
    "\n",
    "    # Containers for batch predictions\n",
    "    patch_boundaries_list = []\n",
    "    counter = 0\n",
    "\n",
    "    # Stride along Z axis:  \n",
    "    for z_start in range(0, prediction_array.shape[2], z_stride):\n",
    "        z_end = z_start + 24\n",
    "        if (np.count_nonzero(image[z_start:z_end, :, :]) > 1):\n",
    "            patch_boundaries_list.append([z_start, z_end])\n",
    "    for patch_index in range(0, len(patch_boundaries_list)):\n",
    "        # patch_boundaries in current batch\n",
    "        temporal_boundaries = patch_boundaries_list[patch_index]\n",
    "        temp_patches = []\n",
    "        # Extracting patches for prediction\n",
    "        current_patch = image_paded[temporal_boundaries[0]:temporal_boundaries[1],\n",
    "                        16:48,\n",
    "                        16:48]\n",
    "        current_patch = np.expand_dims(current_patch, axis=0)\n",
    "        # Updating prediction_array and coverage_array\n",
    "        predicted_patch = model.predict(np.expand_dims(current_patch, axis=-1))\n",
    "\n",
    "        # 0 belső maszk 1 külső maszk 2 differencia\n",
    "\n",
    "        prediction = predicted_patch[which_prediction]\n",
    "\n",
    "        prediction = np.reshape(prediction, [24, 32, 32])\n",
    "\n",
    "        prediction_array[temporal_boundaries[0]:temporal_boundaries[1],\n",
    "        16:48,\n",
    "        16:48] += prediction\n",
    "\n",
    "        # print(prediction_array[32, 32, 32])\n",
    "\n",
    "        coverage_array[temporal_boundaries[0]:temporal_boundaries[1],\n",
    "        :,\n",
    "        :] += 1\n",
    "\n",
    "    coverage_array = np.maximum(coverage_array, np.ones(coverage_array.shape))\n",
    "    # Taking the average prediction value for the pixels\n",
    "    prediction_array = np.divide(prediction_array, coverage_array)\n",
    "    # print(prediction_array[32,32,32])\n",
    "    # Removing the prediction values outside of the CT  \n",
    "    prediction_array = prediction_array[0:size_Z, 0:size_Y, 0:size_X]\n",
    "\n",
    "    # The average prediction value is continuous between 0 and 1,   \n",
    "    # so for the segmentation we have to threshold it   \n",
    "    prediction_array = (prediction_array > 1 / 2) * 1\n",
    "\n",
    "    return prediction_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_from_dicom(contour_file_name):\n",
    "    ds = pydicom.dcmread(contour_file_name)\n",
    "    pixels = np.array(ds.pixel_array)\n",
    "    pixels = np.where(pixels > 0, 1, 0)\n",
    "    return pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vessel(image_path):\n",
    "    '''\n",
    "    retrun DL segmentation and original segmentation of one plaque.\n",
    "    '''\n",
    "    image_dicom=pydicom.dcmread(image_path)\n",
    "    image = image_dicom.pixel_array\n",
    "\n",
    "    dif_prediction = full_cta_model_evaluation(image = image, model = model, z_stride = 12, which_prediction=2) \n",
    "    #contour of plaque area, segmented by DL\n",
    "    mask_1_prediction= full_cta_model_evaluation(image = image, model = model, z_stride = 12, which_prediction=0)\n",
    "    #contour of inner vessel wall segmented by DL\n",
    "    mask_2_prediction= full_cta_model_evaluation(image = image, model = model, z_stride = 12, which_prediction=1)  \n",
    "    #contour of outer vessel wall segmented by DL\n",
    "\n",
    "    mask_1_path = os.path.join(basic_path, image_name[:-13]+\"Contour1.dcm\") \n",
    "    #if the naming process of the mevislab code is not ovewritten, this loads the relevant files\n",
    "    mask_2_path = os.path.join(basic_path, image_name[:-13]+\"Contour2.dcm\")\n",
    "    mask_1 = mask_from_dicom(mask_1_path) #contour of inner vessel wall of the original segmentation\n",
    "    mask_2 = mask_from_dicom(mask_2_path) #contour of outer vessel wall of the original segmentation\n",
    "    dif_test=mask_2-mask_1 #contour of the plaque area of the original segmentation\n",
    "        \n",
    "    return image, dif_test, dif_prediction, mask_1_prediction, mask_2_prediction, mask_1, mask_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, dif_test, dif_prediction, mask_1_prediction, mask_2_prediction, mask_1, mask_2 = one_vessel(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
