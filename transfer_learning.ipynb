{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from functools import partial, update_wrapper\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "\n",
    "# Retrieving blocks of a numpy array\n",
    "from skimage.util import view_as_blocks\n",
    "# Retrieving blocks of a numpy array with given stride sizes\n",
    "from skimage.util.shape import view_as_windows\n",
    "from random import randint\n",
    "\n",
    "from tqdm import tqdm\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Flatten, Dense, concatenate, Conv2D, Conv3D, MaxPooling2D, MaxPooling3D, Conv2DTranspose, Conv3DTranspose\n",
    "from keras.layers import Activation, add, multiply, Lambda\n",
    "from keras.layers import AveragePooling2D, AveragePooling3D, average, UpSampling2D, UpSampling3D, Dropout\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.initializers import glorot_normal, random_normal, random_uniform\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from script_libr import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helps with gpu overloading errors\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_path = \"Mevislab_Output\" #path of the mevislab output files\n",
    "\n",
    "basic_path2 = \"Mevislab_Input\" #path of the original file, to be able to acces the .xlm-s\n",
    "\n",
    "model_logs=\"/Model_logs/checkpoints/\"\n",
    "\n",
    "model_checkpoint=model_logs+'cyclic_attn_unet_3D_plaque_epoch_{epoch:03d}_valdsc_{val_dif_dsc:03f}.h5'\n",
    "\n",
    "traintype='Plakk'\n",
    "\n",
    "base_dir_to_save = \"/patches/Plakk/\"\n",
    "\n",
    "base_dir_pred='/predictions/Plakk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for direct in [model_logs,bds,base_dir_to_save,bdr,base_dir_pred]:\n",
    "    #direct=direct.rstrip('/')\n",
    "    if not os.path.exists(direct):\n",
    "        os.mkdir(direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = os.listdir(basic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/data/Model_logs/checkpoints2/cyclic_attn_unet_3D_plaque_epoch_017_valdsc_0.660232.h5'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/mnt/data/Model_logs/checkpoints2/cyclic_attn_unet_3D_plaque_epoch_017_valdsc_0.660232.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {'alpha': 0.6635482209772863, 'dropout': 0.0022118370088630712, 'gamma': 0.7940638705632237, 'kernel_power': 8, 'learning_rate': 0.00015099469943923109, 'loss_type': 0, 'smooth': 1, 'unet_type': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arg():\n",
    "    def __init__(self):\n",
    "        self.alpha=0.7\n",
    "        self.gamma=0.75\n",
    "        self.loss_type=1 #1 for focal tversky\n",
    "        self.unet_type=0 #1 for attn unet\n",
    "        self.smooth=1\n",
    "        self.learning_rate=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.6635482209772863, 'dropout': 0.0022118370088630712, 'gamma': 0.7940638705632237, 'kernel_power': 8, 'learning_rate': 0.00015099469943923109, 'loss_type': 0, 'smooth': 1, 'unet_type': 2}\n"
     ]
    }
   ],
   "source": [
    "args=arg()\n",
    "args.loss_type=arguments['loss_type']\n",
    "args.unet_type=arguments['unet_type']\n",
    "args.smooth=arguments['smooth']\n",
    "args.alpha=arguments['alpha']\n",
    "args.gamma=arguments['gamma']\n",
    "args.learning_rate=arguments['learning_rate']\n",
    "args.dropout=arguments['dropout']\n",
    "args.kernel_power=arguments['kernel_power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tiny_attn_unet3D(Adam(learning_rate=args.learning_rate), (24,32,32,1),args)\n",
    "model.load_weights('model_internal_dataset.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = os.listdir(basic_path)\n",
    "all_pairs = get_pairs(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:00, 1635798.15it/s]\n",
      "835it [00:13, 59.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['PA00095',\n",
       " 'PA00240',\n",
       " 'PA00171',\n",
       " 'PA00147',\n",
       " 'PA00199',\n",
       " 'PA00140',\n",
       " 'PA00192',\n",
       " 'PA00162',\n",
       " 'PA00156',\n",
       " 'PA00086',\n",
       " 'PA00160',\n",
       " 'PA00139',\n",
       " 'PA00151',\n",
       " 'PA00172',\n",
       " 'PA00214',\n",
       " 'PA00091',\n",
       " 'PA00130',\n",
       " 'PA00167',\n",
       " 'PA00168',\n",
       " 'PA00186',\n",
       " 'PA00150',\n",
       " 'PA00215',\n",
       " 'PA00181',\n",
       " 'PA00193',\n",
       " 'PA00131',\n",
       " 'PA00027',\n",
       " 'PA00032']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = {'ID_tuple_list': all_pairs,\n",
    "              'dir_to_save': base_dir_to_save,\n",
    "              'train_val_test_split': [0.6, 0.2, 0.2],\n",
    "              'patch_shape': [64,64,24],\n",
    "              'stride_size': [64,64,12],\n",
    "              'basic_path': basic_path,\n",
    "              'basic_path2': basic_path2,\n",
    "              'truncate': True,\n",
    "              \"plaques_only\": False,\n",
    "              'val_patients': None, \n",
    "              'test_patients': None\n",
    "              }\n",
    "\n",
    "save_all_patch(**param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_images = os.path.join(base_dir_to_save,\"train\",\"images\")\n",
    "path_to_train_masks_1 = os.path.join(base_dir_to_save,\"train\",\"masks_1\")\n",
    "path_to_train_masks_2 = os.path.join(base_dir_to_save,\"train\",\"masks_2\")\n",
    "path_to_train_plaques = os.path.join(base_dir_to_save,\"train\",\"plaques\")\n",
    "\n",
    "path_to_val_images = os.path.join(base_dir_to_save,\"val\",\"images\")\n",
    "path_to_val_masks_1 = os.path.join(base_dir_to_save,\"val\",\"masks_1\")\n",
    "path_to_val_masks_2 = os.path.join(base_dir_to_save,\"val\",\"masks_2\")\n",
    "path_to_val_plaques = os.path.join(base_dir_to_save,\"val\",\"plaques\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = os.listdir(path_to_train_images)\n",
    "val_filenames = os.listdir(path_to_val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.zeros(shape = (len(train_filenames), 24, 32, 32, 1), dtype='float32')\n",
    "train_masks_1 = np.zeros(shape = (len(train_filenames), 24, 32, 32, 1), dtype='uint8')\n",
    "train_masks_2 = np.zeros(shape = (len(train_filenames), 24, 32, 32, 1), dtype='uint8')\n",
    "train_dif = np.zeros(shape = (len(train_filenames), 24, 32, 32, 1), dtype='uint8')\n",
    "\n",
    "val_images = np.zeros(shape = (len(val_filenames), 24, 32, 32, 1), dtype='float32')\n",
    "val_masks_1 = np.zeros(shape = (len(val_filenames), 24, 32, 32, 1), dtype='uint8')\n",
    "val_masks_2 = np.zeros(shape = (len(val_filenames), 24, 32, 32, 1), dtype='uint8')\n",
    "val_dif  = np.zeros(shape = (len(val_filenames), 24, 32, 32, 1), dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "629it [00:13, 45.17it/s]\n",
      "130it [00:02, 44.71it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, filename in tqdm(enumerate(train_filenames)):\n",
    "    loaded_image = np.load(os.path.join(path_to_train_images, filename))\n",
    "    loaded_mask_1 = np.load(os.path.join(path_to_train_masks_1, filename))\n",
    "    loaded_mask_2 = np.load(os.path.join(path_to_train_masks_2, filename))\n",
    "    loaded_plaque = np.load(os.path.join(path_to_train_plaques, filename))\n",
    "    \n",
    "    train_images[index, :, :, :, 0] = loaded_image\n",
    "    train_masks_1[index, :, :, :, 0] = loaded_mask_1\n",
    "    train_masks_2[index, :, :, :, 0] = loaded_mask_2\n",
    "    train_dif[index, :, :, :, 0] = loaded_plaque\n",
    "    \n",
    "for index, filename in tqdm(enumerate(val_filenames)):\n",
    "    loaded_image = np.load(os.path.join(path_to_val_images, filename))\n",
    "    loaded_mask_1 = np.load(os.path.join(path_to_val_masks_1, filename))\n",
    "    loaded_mask_2 = np.load(os.path.join(path_to_val_masks_2, filename))\n",
    "    loaded_plaque = np.load(os.path.join(path_to_val_plaques, filename))\n",
    "    \n",
    "    val_images[index, :, :, :, 0] = loaded_image\n",
    "    val_masks_1[index, :, :, :, 0] = loaded_mask_1\n",
    "    val_masks_2[index, :, :, :, 0] = loaded_mask_2\n",
    "    val_dif[index, :, :, :, 0] = loaded_plaque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 629 samples, validate on 130 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.1540 - mask_1_loss: 0.0767 - mask_2_loss: 0.0498 - dif_loss: 0.1771 - mask_1_dsc: 0.9233 - mask_2_dsc: 0.9502 - dif_dsc: 0.8229 - dif_tp: 0.8427 - dif_tn: 0.9817 - val_loss: 0.2406 - val_mask_1_loss: 0.1135 - val_mask_2_loss: 0.0832 - val_dif_loss: 0.2754 - val_mask_1_dsc: 0.8865 - val_mask_2_dsc: 0.9168 - val_dif_dsc: 0.7246 - val_dif_tp: 0.7197 - val_dif_tn: 0.9763\n",
      "\n",
      "Epoch 00001: val_dif_dsc improved from -inf to 0.72461, saving model to /mnt/data/Model_logs/checkpointsNRS2/cyclic_attn_unet_3D_plaque_epoch_001_valdsc_0.724614.h5\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.1506 - mask_1_loss: 0.0753 - mask_2_loss: 0.0485 - dif_loss: 0.1727 - mask_1_dsc: 0.9247 - mask_2_dsc: 0.9515 - dif_dsc: 0.8273 - dif_tp: 0.8471 - dif_tn: 0.9823 - val_loss: 0.2520 - val_mask_1_loss: 0.1115 - val_mask_2_loss: 0.0875 - val_dif_loss: 0.2889 - val_mask_1_dsc: 0.8885 - val_mask_2_dsc: 0.9125 - val_dif_dsc: 0.7111 - val_dif_tp: 0.6773 - val_dif_tn: 0.9801\n",
      "\n",
      "Epoch 00002: val_dif_dsc did not improve from 0.72461\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.1496 - mask_1_loss: 0.0743 - mask_2_loss: 0.0484 - dif_loss: 0.1715 - mask_1_dsc: 0.9257 - mask_2_dsc: 0.9516 - dif_dsc: 0.8285 - dif_tp: 0.8472 - dif_tn: 0.9826 - val_loss: 0.2400 - val_mask_1_loss: 0.1116 - val_mask_2_loss: 0.0838 - val_dif_loss: 0.2762 - val_mask_1_dsc: 0.8884 - val_mask_2_dsc: 0.9162 - val_dif_dsc: 0.7238 - val_dif_tp: 0.7178 - val_dif_tn: 0.9766\n",
      "\n",
      "Epoch 00003: val_dif_dsc did not improve from 0.72461\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1469 - mask_1_loss: 0.0730 - mask_2_loss: 0.0472 - dif_loss: 0.1686 - mask_1_dsc: 0.9270 - mask_2_dsc: 0.9528 - dif_dsc: 0.8314 - dif_tp: 0.8499 - dif_tn: 0.9829 - val_loss: 0.2400 - val_mask_1_loss: 0.1102 - val_mask_2_loss: 0.0847 - val_dif_loss: 0.2753 - val_mask_1_dsc: 0.8898 - val_mask_2_dsc: 0.9153 - val_dif_dsc: 0.7247 - val_dif_tp: 0.7291 - val_dif_tn: 0.9750\n",
      "\n",
      "Epoch 00004: val_dif_dsc improved from 0.72461 to 0.72468, saving model to /mnt/data/Model_logs/checkpointsNRS2/cyclic_attn_unet_3D_plaque_epoch_004_valdsc_0.724680.h5\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1465 - mask_1_loss: 0.0716 - mask_2_loss: 0.0471 - dif_loss: 0.1684 - mask_1_dsc: 0.9284 - mask_2_dsc: 0.9529 - dif_dsc: 0.8316 - dif_tp: 0.8507 - dif_tn: 0.9832 - val_loss: 0.2521 - val_mask_1_loss: 0.1170 - val_mask_2_loss: 0.0853 - val_dif_loss: 0.2889 - val_mask_1_dsc: 0.8830 - val_mask_2_dsc: 0.9147 - val_dif_dsc: 0.7111 - val_dif_tp: 0.6778 - val_dif_tn: 0.9798\n",
      "\n",
      "Epoch 00005: val_dif_dsc did not improve from 0.72468\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1427 - mask_1_loss: 0.0710 - mask_2_loss: 0.0465 - dif_loss: 0.1637 - mask_1_dsc: 0.9290 - mask_2_dsc: 0.9535 - dif_dsc: 0.8363 - dif_tp: 0.8553 - dif_tn: 0.9831 - val_loss: 0.2441 - val_mask_1_loss: 0.1126 - val_mask_2_loss: 0.0841 - val_dif_loss: 0.2801 - val_mask_1_dsc: 0.8874 - val_mask_2_dsc: 0.9159 - val_dif_dsc: 0.7199 - val_dif_tp: 0.7007 - val_dif_tn: 0.9783\n",
      "\n",
      "Epoch 00006: val_dif_dsc did not improve from 0.72468\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1427 - mask_1_loss: 0.0707 - mask_2_loss: 0.0463 - dif_loss: 0.1636 - mask_1_dsc: 0.9293 - mask_2_dsc: 0.9537 - dif_dsc: 0.8364 - dif_tp: 0.8545 - dif_tn: 0.9835 - val_loss: 0.2359 - val_mask_1_loss: 0.1139 - val_mask_2_loss: 0.0834 - val_dif_loss: 0.2728 - val_mask_1_dsc: 0.8861 - val_mask_2_dsc: 0.9166 - val_dif_dsc: 0.7272 - val_dif_tp: 0.7588 - val_dif_tn: 0.9712\n",
      "\n",
      "Epoch 00007: val_dif_dsc improved from 0.72468 to 0.72723, saving model to /mnt/data/Model_logs/checkpointsNRS2/cyclic_attn_unet_3D_plaque_epoch_007_valdsc_0.727225.h5\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.1455 - mask_1_loss: 0.0737 - mask_2_loss: 0.0469 - dif_loss: 0.1669 - mask_1_dsc: 0.9263 - mask_2_dsc: 0.9531 - dif_dsc: 0.8331 - dif_tp: 0.8543 - dif_tn: 0.9826 - val_loss: 0.2521 - val_mask_1_loss: 0.1185 - val_mask_2_loss: 0.0875 - val_dif_loss: 0.2912 - val_mask_1_dsc: 0.8815 - val_mask_2_dsc: 0.9125 - val_dif_dsc: 0.7088 - val_dif_tp: 0.7159 - val_dif_tn: 0.9730\n",
      "\n",
      "Epoch 00008: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.1409 - mask_1_loss: 0.0704 - mask_2_loss: 0.0458 - dif_loss: 0.1616 - mask_1_dsc: 0.9296 - mask_2_dsc: 0.9542 - dif_dsc: 0.8384 - dif_tp: 0.8568 - dif_tn: 0.9836 - val_loss: 0.2448 - val_mask_1_loss: 0.1207 - val_mask_2_loss: 0.0846 - val_dif_loss: 0.2812 - val_mask_1_dsc: 0.8793 - val_mask_2_dsc: 0.9154 - val_dif_dsc: 0.7188 - val_dif_tp: 0.7343 - val_dif_tn: 0.9722\n",
      "\n",
      "Epoch 00009: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.1387 - mask_1_loss: 0.0691 - mask_2_loss: 0.0452 - dif_loss: 0.1592 - mask_1_dsc: 0.9309 - mask_2_dsc: 0.9548 - dif_dsc: 0.8408 - dif_tp: 0.8602 - dif_tn: 0.9837 - val_loss: 0.2534 - val_mask_1_loss: 0.1255 - val_mask_2_loss: 0.0878 - val_dif_loss: 0.2926 - val_mask_1_dsc: 0.8745 - val_mask_2_dsc: 0.9122 - val_dif_dsc: 0.7074 - val_dif_tp: 0.7381 - val_dif_tn: 0.9698\n",
      "\n",
      "Epoch 00010: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 11/100\n",
      " - 4s - loss: 0.1377 - mask_1_loss: 0.0671 - mask_2_loss: 0.0455 - dif_loss: 0.1579 - mask_1_dsc: 0.9329 - mask_2_dsc: 0.9545 - dif_dsc: 0.8421 - dif_tp: 0.8605 - dif_tn: 0.9837 - val_loss: 0.2462 - val_mask_1_loss: 0.1144 - val_mask_2_loss: 0.0845 - val_dif_loss: 0.2816 - val_mask_1_dsc: 0.8856 - val_mask_2_dsc: 0.9155 - val_dif_dsc: 0.7184 - val_dif_tp: 0.7065 - val_dif_tn: 0.9767\n",
      "\n",
      "Epoch 00011: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 12/100\n",
      " - 4s - loss: 0.1359 - mask_1_loss: 0.0671 - mask_2_loss: 0.0451 - dif_loss: 0.1560 - mask_1_dsc: 0.9329 - mask_2_dsc: 0.9549 - dif_dsc: 0.8440 - dif_tp: 0.8621 - dif_tn: 0.9841 - val_loss: 0.2441 - val_mask_1_loss: 0.1157 - val_mask_2_loss: 0.0854 - val_dif_loss: 0.2805 - val_mask_1_dsc: 0.8843 - val_mask_2_dsc: 0.9146 - val_dif_dsc: 0.7195 - val_dif_tp: 0.7338 - val_dif_tn: 0.9729\n",
      "\n",
      "Epoch 00012: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 13/100\n",
      " - 4s - loss: 0.1378 - mask_1_loss: 0.0670 - mask_2_loss: 0.0452 - dif_loss: 0.1584 - mask_1_dsc: 0.9330 - mask_2_dsc: 0.9548 - dif_dsc: 0.8416 - dif_tp: 0.8623 - dif_tn: 0.9837 - val_loss: 0.2539 - val_mask_1_loss: 0.1208 - val_mask_2_loss: 0.0840 - val_dif_loss: 0.2904 - val_mask_1_dsc: 0.8792 - val_mask_2_dsc: 0.9160 - val_dif_dsc: 0.7096 - val_dif_tp: 0.6844 - val_dif_tn: 0.9779\n",
      "\n",
      "Epoch 00013: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 14/100\n",
      " - 4s - loss: 0.1341 - mask_1_loss: 0.0652 - mask_2_loss: 0.0442 - dif_loss: 0.1540 - mask_1_dsc: 0.9348 - mask_2_dsc: 0.9558 - dif_dsc: 0.8460 - dif_tp: 0.8629 - dif_tn: 0.9843 - val_loss: 0.2496 - val_mask_1_loss: 0.1158 - val_mask_2_loss: 0.0867 - val_dif_loss: 0.2862 - val_mask_1_dsc: 0.8842 - val_mask_2_dsc: 0.9133 - val_dif_dsc: 0.7138 - val_dif_tp: 0.7102 - val_dif_tn: 0.9751\n",
      "\n",
      "Epoch 00014: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 15/100\n",
      " - 4s - loss: 0.1348 - mask_1_loss: 0.0664 - mask_2_loss: 0.0444 - dif_loss: 0.1547 - mask_1_dsc: 0.9336 - mask_2_dsc: 0.9556 - dif_dsc: 0.8453 - dif_tp: 0.8640 - dif_tn: 0.9841 - val_loss: 0.2405 - val_mask_1_loss: 0.1135 - val_mask_2_loss: 0.0866 - val_dif_loss: 0.2775 - val_mask_1_dsc: 0.8865 - val_mask_2_dsc: 0.9134 - val_dif_dsc: 0.7225 - val_dif_tp: 0.7536 - val_dif_tn: 0.9711\n",
      "\n",
      "Epoch 00015: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 16/100\n",
      " - 4s - loss: 0.1326 - mask_1_loss: 0.0647 - mask_2_loss: 0.0440 - dif_loss: 0.1523 - mask_1_dsc: 0.9353 - mask_2_dsc: 0.9560 - dif_dsc: 0.8477 - dif_tp: 0.8644 - dif_tn: 0.9846 - val_loss: 0.2660 - val_mask_1_loss: 0.1206 - val_mask_2_loss: 0.0880 - val_dif_loss: 0.3049 - val_mask_1_dsc: 0.8794 - val_mask_2_dsc: 0.9120 - val_dif_dsc: 0.6951 - val_dif_tp: 0.6539 - val_dif_tn: 0.9797\n",
      "\n",
      "Epoch 00016: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 17/100\n",
      " - 4s - loss: 0.1323 - mask_1_loss: 0.0640 - mask_2_loss: 0.0439 - dif_loss: 0.1518 - mask_1_dsc: 0.9360 - mask_2_dsc: 0.9561 - dif_dsc: 0.8482 - dif_tp: 0.8658 - dif_tn: 0.9845 - val_loss: 0.2525 - val_mask_1_loss: 0.1157 - val_mask_2_loss: 0.0859 - val_dif_loss: 0.2899 - val_mask_1_dsc: 0.8843 - val_mask_2_dsc: 0.9141 - val_dif_dsc: 0.7101 - val_dif_tp: 0.6937 - val_dif_tn: 0.9770\n",
      "\n",
      "Epoch 00017: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 18/100\n",
      " - 4s - loss: 0.1283 - mask_1_loss: 0.0626 - mask_2_loss: 0.0428 - dif_loss: 0.1472 - mask_1_dsc: 0.9374 - mask_2_dsc: 0.9572 - dif_dsc: 0.8528 - dif_tp: 0.8703 - dif_tn: 0.9848 - val_loss: 0.2528 - val_mask_1_loss: 0.1200 - val_mask_2_loss: 0.0874 - val_dif_loss: 0.2912 - val_mask_1_dsc: 0.8800 - val_mask_2_dsc: 0.9126 - val_dif_dsc: 0.7088 - val_dif_tp: 0.6985 - val_dif_tn: 0.9761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00018: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 19/100\n",
      " - 4s - loss: 0.1260 - mask_1_loss: 0.0614 - mask_2_loss: 0.0421 - dif_loss: 0.1447 - mask_1_dsc: 0.9386 - mask_2_dsc: 0.9579 - dif_dsc: 0.8553 - dif_tp: 0.8723 - dif_tn: 0.9852 - val_loss: 0.2482 - val_mask_1_loss: 0.1145 - val_mask_2_loss: 0.0861 - val_dif_loss: 0.2839 - val_mask_1_dsc: 0.8855 - val_mask_2_dsc: 0.9139 - val_dif_dsc: 0.7161 - val_dif_tp: 0.7063 - val_dif_tn: 0.9761\n",
      "\n",
      "Epoch 00019: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 20/100\n",
      " - 4s - loss: 0.1324 - mask_1_loss: 0.0637 - mask_2_loss: 0.0445 - dif_loss: 0.1521 - mask_1_dsc: 0.9363 - mask_2_dsc: 0.9555 - dif_dsc: 0.8479 - dif_tp: 0.8658 - dif_tn: 0.9843 - val_loss: 0.2603 - val_mask_1_loss: 0.1189 - val_mask_2_loss: 0.0880 - val_dif_loss: 0.2995 - val_mask_1_dsc: 0.8811 - val_mask_2_dsc: 0.9120 - val_dif_dsc: 0.7005 - val_dif_tp: 0.6742 - val_dif_tn: 0.9777\n",
      "\n",
      "Epoch 00020: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 21/100\n",
      " - 4s - loss: 0.1293 - mask_1_loss: 0.0626 - mask_2_loss: 0.0432 - dif_loss: 0.1485 - mask_1_dsc: 0.9374 - mask_2_dsc: 0.9568 - dif_dsc: 0.8515 - dif_tp: 0.8685 - dif_tn: 0.9848 - val_loss: 0.2561 - val_mask_1_loss: 0.1281 - val_mask_2_loss: 0.0881 - val_dif_loss: 0.2951 - val_mask_1_dsc: 0.8719 - val_mask_2_dsc: 0.9119 - val_dif_dsc: 0.7049 - val_dif_tp: 0.7296 - val_dif_tn: 0.9702\n",
      "\n",
      "Epoch 00021: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 22/100\n",
      " - 4s - loss: 0.1269 - mask_1_loss: 0.0622 - mask_2_loss: 0.0425 - dif_loss: 0.1453 - mask_1_dsc: 0.9378 - mask_2_dsc: 0.9575 - dif_dsc: 0.8547 - dif_tp: 0.8713 - dif_tn: 0.9851 - val_loss: 0.2414 - val_mask_1_loss: 0.1121 - val_mask_2_loss: 0.0849 - val_dif_loss: 0.2776 - val_mask_1_dsc: 0.8879 - val_mask_2_dsc: 0.9151 - val_dif_dsc: 0.7224 - val_dif_tp: 0.7351 - val_dif_tn: 0.9734\n",
      "\n",
      "Epoch 00022: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 23/100\n",
      " - 4s - loss: 0.1251 - mask_1_loss: 0.0601 - mask_2_loss: 0.0421 - dif_loss: 0.1438 - mask_1_dsc: 0.9399 - mask_2_dsc: 0.9579 - dif_dsc: 0.8562 - dif_tp: 0.8726 - dif_tn: 0.9854 - val_loss: 0.2576 - val_mask_1_loss: 0.1201 - val_mask_2_loss: 0.0850 - val_dif_loss: 0.2948 - val_mask_1_dsc: 0.8799 - val_mask_2_dsc: 0.9150 - val_dif_dsc: 0.7052 - val_dif_tp: 0.6780 - val_dif_tn: 0.9780\n",
      "\n",
      "Epoch 00023: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 24/100\n",
      " - 4s - loss: 0.1250 - mask_1_loss: 0.0613 - mask_2_loss: 0.0418 - dif_loss: 0.1434 - mask_1_dsc: 0.9387 - mask_2_dsc: 0.9582 - dif_dsc: 0.8566 - dif_tp: 0.8711 - dif_tn: 0.9856 - val_loss: 0.2459 - val_mask_1_loss: 0.1122 - val_mask_2_loss: 0.0864 - val_dif_loss: 0.2816 - val_mask_1_dsc: 0.8878 - val_mask_2_dsc: 0.9136 - val_dif_dsc: 0.7184 - val_dif_tp: 0.7130 - val_dif_tn: 0.9758\n",
      "\n",
      "Epoch 00024: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 25/100\n",
      " - 4s - loss: 0.1217 - mask_1_loss: 0.0578 - mask_2_loss: 0.0414 - dif_loss: 0.1395 - mask_1_dsc: 0.9422 - mask_2_dsc: 0.9586 - dif_dsc: 0.8605 - dif_tp: 0.8763 - dif_tn: 0.9859 - val_loss: 0.2489 - val_mask_1_loss: 0.1183 - val_mask_2_loss: 0.0873 - val_dif_loss: 0.2845 - val_mask_1_dsc: 0.8817 - val_mask_2_dsc: 0.9127 - val_dif_dsc: 0.7155 - val_dif_tp: 0.7235 - val_dif_tn: 0.9732\n",
      "\n",
      "Epoch 00025: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 26/100\n",
      " - 4s - loss: 0.1221 - mask_1_loss: 0.0584 - mask_2_loss: 0.0412 - dif_loss: 0.1402 - mask_1_dsc: 0.9416 - mask_2_dsc: 0.9588 - dif_dsc: 0.8598 - dif_tp: 0.8748 - dif_tn: 0.9858 - val_loss: 0.2549 - val_mask_1_loss: 0.1160 - val_mask_2_loss: 0.0884 - val_dif_loss: 0.2943 - val_mask_1_dsc: 0.8840 - val_mask_2_dsc: 0.9116 - val_dif_dsc: 0.7057 - val_dif_tp: 0.6887 - val_dif_tn: 0.9768\n",
      "\n",
      "Epoch 00026: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 27/100\n",
      " - 4s - loss: 0.1203 - mask_1_loss: 0.0573 - mask_2_loss: 0.0404 - dif_loss: 0.1380 - mask_1_dsc: 0.9427 - mask_2_dsc: 0.9596 - dif_dsc: 0.8620 - dif_tp: 0.8768 - dif_tn: 0.9863 - val_loss: 0.2582 - val_mask_1_loss: 0.1184 - val_mask_2_loss: 0.0871 - val_dif_loss: 0.2953 - val_mask_1_dsc: 0.8816 - val_mask_2_dsc: 0.9129 - val_dif_dsc: 0.7047 - val_dif_tp: 0.6764 - val_dif_tn: 0.9777\n",
      "\n",
      "Epoch 00027: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 28/100\n",
      " - 4s - loss: 0.1182 - mask_1_loss: 0.0565 - mask_2_loss: 0.0398 - dif_loss: 0.1358 - mask_1_dsc: 0.9435 - mask_2_dsc: 0.9602 - dif_dsc: 0.8642 - dif_tp: 0.8772 - dif_tn: 0.9865 - val_loss: 0.2574 - val_mask_1_loss: 0.1179 - val_mask_2_loss: 0.0882 - val_dif_loss: 0.2964 - val_mask_1_dsc: 0.8821 - val_mask_2_dsc: 0.9118 - val_dif_dsc: 0.7036 - val_dif_tp: 0.6965 - val_dif_tn: 0.9748\n",
      "\n",
      "Epoch 00028: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 29/100\n",
      " - 4s - loss: 0.1200 - mask_1_loss: 0.0585 - mask_2_loss: 0.0402 - dif_loss: 0.1375 - mask_1_dsc: 0.9415 - mask_2_dsc: 0.9598 - dif_dsc: 0.8625 - dif_tp: 0.8768 - dif_tn: 0.9862 - val_loss: 0.2553 - val_mask_1_loss: 0.1198 - val_mask_2_loss: 0.0858 - val_dif_loss: 0.2921 - val_mask_1_dsc: 0.8802 - val_mask_2_dsc: 0.9142 - val_dif_dsc: 0.7079 - val_dif_tp: 0.6880 - val_dif_tn: 0.9778\n",
      "\n",
      "Epoch 00029: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 30/100\n",
      " - 4s - loss: 0.1140 - mask_1_loss: 0.0551 - mask_2_loss: 0.0382 - dif_loss: 0.1307 - mask_1_dsc: 0.9449 - mask_2_dsc: 0.9618 - dif_dsc: 0.8693 - dif_tp: 0.8828 - dif_tn: 0.9869 - val_loss: 0.2588 - val_mask_1_loss: 0.1175 - val_mask_2_loss: 0.0858 - val_dif_loss: 0.2976 - val_mask_1_dsc: 0.8825 - val_mask_2_dsc: 0.9142 - val_dif_dsc: 0.7024 - val_dif_tp: 0.6601 - val_dif_tn: 0.9810\n",
      "\n",
      "Epoch 00030: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 31/100\n",
      " - 4s - loss: 0.1093 - mask_1_loss: 0.0527 - mask_2_loss: 0.0369 - dif_loss: 0.1256 - mask_1_dsc: 0.9473 - mask_2_dsc: 0.9631 - dif_dsc: 0.8744 - dif_tp: 0.8868 - dif_tn: 0.9876 - val_loss: 0.2460 - val_mask_1_loss: 0.1142 - val_mask_2_loss: 0.0846 - val_dif_loss: 0.2827 - val_mask_1_dsc: 0.8858 - val_mask_2_dsc: 0.9154 - val_dif_dsc: 0.7173 - val_dif_tp: 0.7121 - val_dif_tn: 0.9755\n",
      "\n",
      "Epoch 00031: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 32/100\n",
      " - 4s - loss: 0.1096 - mask_1_loss: 0.0524 - mask_2_loss: 0.0371 - dif_loss: 0.1258 - mask_1_dsc: 0.9476 - mask_2_dsc: 0.9629 - dif_dsc: 0.8742 - dif_tp: 0.8858 - dif_tn: 0.9877 - val_loss: 0.2500 - val_mask_1_loss: 0.1140 - val_mask_2_loss: 0.0849 - val_dif_loss: 0.2870 - val_mask_1_dsc: 0.8860 - val_mask_2_dsc: 0.9151 - val_dif_dsc: 0.7130 - val_dif_tp: 0.6879 - val_dif_tn: 0.9786\n",
      "\n",
      "Epoch 00032: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 33/100\n",
      " - 4s - loss: 0.1051 - mask_1_loss: 0.0509 - mask_2_loss: 0.0359 - dif_loss: 0.1204 - mask_1_dsc: 0.9491 - mask_2_dsc: 0.9641 - dif_dsc: 0.8796 - dif_tp: 0.8914 - dif_tn: 0.9880 - val_loss: 0.2463 - val_mask_1_loss: 0.1118 - val_mask_2_loss: 0.0839 - val_dif_loss: 0.2824 - val_mask_1_dsc: 0.8882 - val_mask_2_dsc: 0.9161 - val_dif_dsc: 0.7176 - val_dif_tp: 0.7027 - val_dif_tn: 0.9773\n",
      "\n",
      "Epoch 00033: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 34/100\n",
      " - 4s - loss: 0.1052 - mask_1_loss: 0.0509 - mask_2_loss: 0.0360 - dif_loss: 0.1207 - mask_1_dsc: 0.9491 - mask_2_dsc: 0.9640 - dif_dsc: 0.8793 - dif_tp: 0.8909 - dif_tn: 0.9881 - val_loss: 0.2551 - val_mask_1_loss: 0.1137 - val_mask_2_loss: 0.0867 - val_dif_loss: 0.2937 - val_mask_1_dsc: 0.8863 - val_mask_2_dsc: 0.9133 - val_dif_dsc: 0.7063 - val_dif_tp: 0.6753 - val_dif_tn: 0.9792\n",
      "\n",
      "Epoch 00034: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 35/100\n",
      " - 4s - loss: 0.1015 - mask_1_loss: 0.0490 - mask_2_loss: 0.0351 - dif_loss: 0.1164 - mask_1_dsc: 0.9510 - mask_2_dsc: 0.9649 - dif_dsc: 0.8836 - dif_tp: 0.8924 - dif_tn: 0.9887 - val_loss: 0.2543 - val_mask_1_loss: 0.1174 - val_mask_2_loss: 0.0855 - val_dif_loss: 0.2924 - val_mask_1_dsc: 0.8826 - val_mask_2_dsc: 0.9145 - val_dif_dsc: 0.7076 - val_dif_tp: 0.6862 - val_dif_tn: 0.9781\n",
      "\n",
      "Epoch 00035: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 36/100\n",
      " - 4s - loss: 0.1033 - mask_1_loss: 0.0489 - mask_2_loss: 0.0356 - dif_loss: 0.1185 - mask_1_dsc: 0.9511 - mask_2_dsc: 0.9644 - dif_dsc: 0.8815 - dif_tp: 0.8932 - dif_tn: 0.9883 - val_loss: 0.2512 - val_mask_1_loss: 0.1125 - val_mask_2_loss: 0.0875 - val_dif_loss: 0.2881 - val_mask_1_dsc: 0.8875 - val_mask_2_dsc: 0.9125 - val_dif_dsc: 0.7119 - val_dif_tp: 0.6992 - val_dif_tn: 0.9760\n",
      "\n",
      "Epoch 00036: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 4s - loss: 0.1017 - mask_1_loss: 0.0485 - mask_2_loss: 0.0355 - dif_loss: 0.1166 - mask_1_dsc: 0.9515 - mask_2_dsc: 0.9645 - dif_dsc: 0.8834 - dif_tp: 0.8935 - dif_tn: 0.9886 - val_loss: 0.2533 - val_mask_1_loss: 0.1145 - val_mask_2_loss: 0.0887 - val_dif_loss: 0.2898 - val_mask_1_dsc: 0.8855 - val_mask_2_dsc: 0.9113 - val_dif_dsc: 0.7102 - val_dif_tp: 0.6992 - val_dif_tn: 0.9755\n",
      "\n",
      "Epoch 00037: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 38/100\n",
      " - 4s - loss: 0.0986 - mask_1_loss: 0.0478 - mask_2_loss: 0.0340 - dif_loss: 0.1131 - mask_1_dsc: 0.9522 - mask_2_dsc: 0.9660 - dif_dsc: 0.8869 - dif_tp: 0.8972 - dif_tn: 0.9889 - val_loss: 0.2564 - val_mask_1_loss: 0.1144 - val_mask_2_loss: 0.0865 - val_dif_loss: 0.2943 - val_mask_1_dsc: 0.8856 - val_mask_2_dsc: 0.9135 - val_dif_dsc: 0.7057 - val_dif_tp: 0.6715 - val_dif_tn: 0.9794\n",
      "\n",
      "Epoch 00038: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 39/100\n",
      " - 4s - loss: 0.0970 - mask_1_loss: 0.0465 - mask_2_loss: 0.0334 - dif_loss: 0.1114 - mask_1_dsc: 0.9535 - mask_2_dsc: 0.9666 - dif_dsc: 0.8886 - dif_tp: 0.8983 - dif_tn: 0.9893 - val_loss: 0.2486 - val_mask_1_loss: 0.1136 - val_mask_2_loss: 0.0849 - val_dif_loss: 0.2848 - val_mask_1_dsc: 0.8864 - val_mask_2_dsc: 0.9151 - val_dif_dsc: 0.7152 - val_dif_tp: 0.7022 - val_dif_tn: 0.9771\n",
      "\n",
      "Epoch 00039: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 40/100\n",
      " - 4s - loss: 0.0943 - mask_1_loss: 0.0451 - mask_2_loss: 0.0327 - dif_loss: 0.1078 - mask_1_dsc: 0.9549 - mask_2_dsc: 0.9673 - dif_dsc: 0.8922 - dif_tp: 0.9019 - dif_tn: 0.9895 - val_loss: 0.2514 - val_mask_1_loss: 0.1136 - val_mask_2_loss: 0.0853 - val_dif_loss: 0.2883 - val_mask_1_dsc: 0.8864 - val_mask_2_dsc: 0.9147 - val_dif_dsc: 0.7117 - val_dif_tp: 0.6880 - val_dif_tn: 0.9783\n",
      "\n",
      "Epoch 00040: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 41/100\n",
      " - 4s - loss: 0.0930 - mask_1_loss: 0.0447 - mask_2_loss: 0.0321 - dif_loss: 0.1067 - mask_1_dsc: 0.9553 - mask_2_dsc: 0.9679 - dif_dsc: 0.8933 - dif_tp: 0.9016 - dif_tn: 0.9896 - val_loss: 0.2540 - val_mask_1_loss: 0.1134 - val_mask_2_loss: 0.0868 - val_dif_loss: 0.2909 - val_mask_1_dsc: 0.8866 - val_mask_2_dsc: 0.9132 - val_dif_dsc: 0.7091 - val_dif_tp: 0.6822 - val_dif_tn: 0.9787\n",
      "\n",
      "Epoch 00041: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 42/100\n",
      " - 4s - loss: 0.0910 - mask_1_loss: 0.0438 - mask_2_loss: 0.0315 - dif_loss: 0.1043 - mask_1_dsc: 0.9562 - mask_2_dsc: 0.9685 - dif_dsc: 0.8957 - dif_tp: 0.9036 - dif_tn: 0.9899 - val_loss: 0.2513 - val_mask_1_loss: 0.1124 - val_mask_2_loss: 0.0859 - val_dif_loss: 0.2884 - val_mask_1_dsc: 0.8876 - val_mask_2_dsc: 0.9141 - val_dif_dsc: 0.7116 - val_dif_tp: 0.6868 - val_dif_tn: 0.9787\n",
      "\n",
      "Epoch 00042: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 43/100\n",
      " - 4s - loss: 0.0888 - mask_1_loss: 0.0433 - mask_2_loss: 0.0308 - dif_loss: 0.1017 - mask_1_dsc: 0.9567 - mask_2_dsc: 0.9692 - dif_dsc: 0.8983 - dif_tp: 0.9069 - dif_tn: 0.9901 - val_loss: 0.2580 - val_mask_1_loss: 0.1124 - val_mask_2_loss: 0.0873 - val_dif_loss: 0.2959 - val_mask_1_dsc: 0.8876 - val_mask_2_dsc: 0.9127 - val_dif_dsc: 0.7041 - val_dif_tp: 0.6628 - val_dif_tn: 0.9809\n",
      "\n",
      "Epoch 00043: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 44/100\n",
      " - 4s - loss: 0.0878 - mask_1_loss: 0.0423 - mask_2_loss: 0.0307 - dif_loss: 0.1009 - mask_1_dsc: 0.9577 - mask_2_dsc: 0.9693 - dif_dsc: 0.8991 - dif_tp: 0.9073 - dif_tn: 0.9903 - val_loss: 0.2539 - val_mask_1_loss: 0.1141 - val_mask_2_loss: 0.0850 - val_dif_loss: 0.2907 - val_mask_1_dsc: 0.8859 - val_mask_2_dsc: 0.9150 - val_dif_dsc: 0.7093 - val_dif_tp: 0.6773 - val_dif_tn: 0.9796\n",
      "\n",
      "Epoch 00044: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 45/100\n",
      " - 4s - loss: 0.0870 - mask_1_loss: 0.0419 - mask_2_loss: 0.0304 - dif_loss: 0.0997 - mask_1_dsc: 0.9581 - mask_2_dsc: 0.9696 - dif_dsc: 0.9003 - dif_tp: 0.9082 - dif_tn: 0.9904 - val_loss: 0.2515 - val_mask_1_loss: 0.1134 - val_mask_2_loss: 0.0847 - val_dif_loss: 0.2883 - val_mask_1_dsc: 0.8866 - val_mask_2_dsc: 0.9153 - val_dif_dsc: 0.7117 - val_dif_tp: 0.6820 - val_dif_tn: 0.9791\n",
      "\n",
      "Epoch 00045: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 46/100\n",
      " - 4s - loss: 0.0850 - mask_1_loss: 0.0409 - mask_2_loss: 0.0297 - dif_loss: 0.0974 - mask_1_dsc: 0.9591 - mask_2_dsc: 0.9703 - dif_dsc: 0.9026 - dif_tp: 0.9097 - dif_tn: 0.9906 - val_loss: 0.2570 - val_mask_1_loss: 0.1137 - val_mask_2_loss: 0.0861 - val_dif_loss: 0.2952 - val_mask_1_dsc: 0.8863 - val_mask_2_dsc: 0.9139 - val_dif_dsc: 0.7048 - val_dif_tp: 0.6667 - val_dif_tn: 0.9802\n",
      "\n",
      "Epoch 00046: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 47/100\n",
      " - 4s - loss: 0.0842 - mask_1_loss: 0.0407 - mask_2_loss: 0.0298 - dif_loss: 0.0965 - mask_1_dsc: 0.9593 - mask_2_dsc: 0.9702 - dif_dsc: 0.9035 - dif_tp: 0.9099 - dif_tn: 0.9908 - val_loss: 0.2528 - val_mask_1_loss: 0.1140 - val_mask_2_loss: 0.0851 - val_dif_loss: 0.2901 - val_mask_1_dsc: 0.8860 - val_mask_2_dsc: 0.9149 - val_dif_dsc: 0.7099 - val_dif_tp: 0.6782 - val_dif_tn: 0.9794\n",
      "\n",
      "Epoch 00047: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 48/100\n",
      " - 4s - loss: 0.0831 - mask_1_loss: 0.0400 - mask_2_loss: 0.0293 - dif_loss: 0.0954 - mask_1_dsc: 0.9600 - mask_2_dsc: 0.9707 - dif_dsc: 0.9046 - dif_tp: 0.9125 - dif_tn: 0.9909 - val_loss: 0.2566 - val_mask_1_loss: 0.1134 - val_mask_2_loss: 0.0854 - val_dif_loss: 0.2944 - val_mask_1_dsc: 0.8866 - val_mask_2_dsc: 0.9146 - val_dif_dsc: 0.7056 - val_dif_tp: 0.6644 - val_dif_tn: 0.9807\n",
      "\n",
      "Epoch 00048: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 49/100\n",
      " - 4s - loss: 0.0816 - mask_1_loss: 0.0394 - mask_2_loss: 0.0288 - dif_loss: 0.0934 - mask_1_dsc: 0.9606 - mask_2_dsc: 0.9712 - dif_dsc: 0.9066 - dif_tp: 0.9121 - dif_tn: 0.9912 - val_loss: 0.2534 - val_mask_1_loss: 0.1134 - val_mask_2_loss: 0.0854 - val_dif_loss: 0.2910 - val_mask_1_dsc: 0.8866 - val_mask_2_dsc: 0.9146 - val_dif_dsc: 0.7090 - val_dif_tp: 0.6767 - val_dif_tn: 0.9794\n",
      "\n",
      "Epoch 00049: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 50/100\n",
      " - 4s - loss: 0.0807 - mask_1_loss: 0.0389 - mask_2_loss: 0.0284 - dif_loss: 0.0925 - mask_1_dsc: 0.9611 - mask_2_dsc: 0.9716 - dif_dsc: 0.9075 - dif_tp: 0.9149 - dif_tn: 0.9911 - val_loss: 0.2550 - val_mask_1_loss: 0.1143 - val_mask_2_loss: 0.0853 - val_dif_loss: 0.2927 - val_mask_1_dsc: 0.8857 - val_mask_2_dsc: 0.9147 - val_dif_dsc: 0.7073 - val_dif_tp: 0.6723 - val_dif_tn: 0.9797\n",
      "\n",
      "Epoch 00050: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 51/100\n",
      " - 4s - loss: 0.0796 - mask_1_loss: 0.0389 - mask_2_loss: 0.0282 - dif_loss: 0.0912 - mask_1_dsc: 0.9611 - mask_2_dsc: 0.9718 - dif_dsc: 0.9088 - dif_tp: 0.9155 - dif_tn: 0.9912 - val_loss: 0.2537 - val_mask_1_loss: 0.1142 - val_mask_2_loss: 0.0851 - val_dif_loss: 0.2906 - val_mask_1_dsc: 0.8858 - val_mask_2_dsc: 0.9149 - val_dif_dsc: 0.7094 - val_dif_tp: 0.6800 - val_dif_tn: 0.9791\n",
      "\n",
      "Epoch 00051: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 52/100\n",
      " - 4s - loss: 0.0802 - mask_1_loss: 0.0389 - mask_2_loss: 0.0285 - dif_loss: 0.0920 - mask_1_dsc: 0.9611 - mask_2_dsc: 0.9715 - dif_dsc: 0.9080 - dif_tp: 0.9144 - dif_tn: 0.9913 - val_loss: 0.2552 - val_mask_1_loss: 0.1147 - val_mask_2_loss: 0.0852 - val_dif_loss: 0.2926 - val_mask_1_dsc: 0.8853 - val_mask_2_dsc: 0.9148 - val_dif_dsc: 0.7074 - val_dif_tp: 0.6724 - val_dif_tn: 0.9799\n",
      "\n",
      "Epoch 00052: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 53/100\n",
      " - 4s - loss: 0.0802 - mask_1_loss: 0.0390 - mask_2_loss: 0.0283 - dif_loss: 0.0917 - mask_1_dsc: 0.9610 - mask_2_dsc: 0.9717 - dif_dsc: 0.9083 - dif_tp: 0.9144 - dif_tn: 0.9913 - val_loss: 0.2524 - val_mask_1_loss: 0.1137 - val_mask_2_loss: 0.0854 - val_dif_loss: 0.2895 - val_mask_1_dsc: 0.8863 - val_mask_2_dsc: 0.9146 - val_dif_dsc: 0.7105 - val_dif_tp: 0.6859 - val_dif_tn: 0.9786\n",
      "\n",
      "Epoch 00053: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 54/100\n",
      " - 4s - loss: 0.0795 - mask_1_loss: 0.0384 - mask_2_loss: 0.0283 - dif_loss: 0.0909 - mask_1_dsc: 0.9616 - mask_2_dsc: 0.9717 - dif_dsc: 0.9091 - dif_tp: 0.9159 - dif_tn: 0.9912 - val_loss: 0.2574 - val_mask_1_loss: 0.1142 - val_mask_2_loss: 0.0872 - val_dif_loss: 0.2954 - val_mask_1_dsc: 0.8858 - val_mask_2_dsc: 0.9128 - val_dif_dsc: 0.7046 - val_dif_tp: 0.6722 - val_dif_tn: 0.9794\n",
      "\n",
      "Epoch 00054: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 55/100\n",
      " - 4s - loss: 0.0797 - mask_1_loss: 0.0391 - mask_2_loss: 0.0282 - dif_loss: 0.0913 - mask_1_dsc: 0.9609 - mask_2_dsc: 0.9718 - dif_dsc: 0.9087 - dif_tp: 0.9149 - dif_tn: 0.9913 - val_loss: 0.2521 - val_mask_1_loss: 0.1144 - val_mask_2_loss: 0.0852 - val_dif_loss: 0.2895 - val_mask_1_dsc: 0.8856 - val_mask_2_dsc: 0.9148 - val_dif_dsc: 0.7105 - val_dif_tp: 0.6885 - val_dif_tn: 0.9780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00055: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 56/100\n",
      " - 4s - loss: 0.0798 - mask_1_loss: 0.0390 - mask_2_loss: 0.0281 - dif_loss: 0.0912 - mask_1_dsc: 0.9610 - mask_2_dsc: 0.9719 - dif_dsc: 0.9088 - dif_tp: 0.9158 - dif_tn: 0.9912 - val_loss: 0.2575 - val_mask_1_loss: 0.1144 - val_mask_2_loss: 0.0861 - val_dif_loss: 0.2958 - val_mask_1_dsc: 0.8856 - val_mask_2_dsc: 0.9139 - val_dif_dsc: 0.7042 - val_dif_tp: 0.6660 - val_dif_tn: 0.9803\n",
      "\n",
      "Epoch 00056: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 57/100\n",
      " - 4s - loss: 0.0803 - mask_1_loss: 0.0388 - mask_2_loss: 0.0284 - dif_loss: 0.0922 - mask_1_dsc: 0.9612 - mask_2_dsc: 0.9716 - dif_dsc: 0.9078 - dif_tp: 0.9142 - dif_tn: 0.9913 - val_loss: 0.2537 - val_mask_1_loss: 0.1151 - val_mask_2_loss: 0.0851 - val_dif_loss: 0.2910 - val_mask_1_dsc: 0.8849 - val_mask_2_dsc: 0.9149 - val_dif_dsc: 0.7090 - val_dif_tp: 0.6829 - val_dif_tn: 0.9784\n",
      "\n",
      "Epoch 00057: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 58/100\n",
      " - 4s - loss: 0.0823 - mask_1_loss: 0.0394 - mask_2_loss: 0.0291 - dif_loss: 0.0944 - mask_1_dsc: 0.9606 - mask_2_dsc: 0.9709 - dif_dsc: 0.9056 - dif_tp: 0.9132 - dif_tn: 0.9909 - val_loss: 0.2531 - val_mask_1_loss: 0.1151 - val_mask_2_loss: 0.0859 - val_dif_loss: 0.2906 - val_mask_1_dsc: 0.8849 - val_mask_2_dsc: 0.9141 - val_dif_dsc: 0.7094 - val_dif_tp: 0.6883 - val_dif_tn: 0.9779\n",
      "\n",
      "Epoch 00058: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 59/100\n",
      " - 4s - loss: 0.0819 - mask_1_loss: 0.0391 - mask_2_loss: 0.0289 - dif_loss: 0.0940 - mask_1_dsc: 0.9609 - mask_2_dsc: 0.9711 - dif_dsc: 0.9060 - dif_tp: 0.9130 - dif_tn: 0.9910 - val_loss: 0.2716 - val_mask_1_loss: 0.1183 - val_mask_2_loss: 0.0883 - val_dif_loss: 0.3117 - val_mask_1_dsc: 0.8817 - val_mask_2_dsc: 0.9117 - val_dif_dsc: 0.6883 - val_dif_tp: 0.6273 - val_dif_tn: 0.9829\n",
      "\n",
      "Epoch 00059: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 60/100\n",
      " - 4s - loss: 0.0828 - mask_1_loss: 0.0402 - mask_2_loss: 0.0292 - dif_loss: 0.0949 - mask_1_dsc: 0.9598 - mask_2_dsc: 0.9708 - dif_dsc: 0.9051 - dif_tp: 0.9117 - dif_tn: 0.9909 - val_loss: 0.2536 - val_mask_1_loss: 0.1153 - val_mask_2_loss: 0.0856 - val_dif_loss: 0.2915 - val_mask_1_dsc: 0.8847 - val_mask_2_dsc: 0.9144 - val_dif_dsc: 0.7085 - val_dif_tp: 0.6818 - val_dif_tn: 0.9784\n",
      "\n",
      "Epoch 00060: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 61/100\n",
      " - 4s - loss: 0.0828 - mask_1_loss: 0.0391 - mask_2_loss: 0.0291 - dif_loss: 0.0949 - mask_1_dsc: 0.9609 - mask_2_dsc: 0.9709 - dif_dsc: 0.9051 - dif_tp: 0.9124 - dif_tn: 0.9910 - val_loss: 0.2635 - val_mask_1_loss: 0.1164 - val_mask_2_loss: 0.0892 - val_dif_loss: 0.3029 - val_mask_1_dsc: 0.8836 - val_mask_2_dsc: 0.9108 - val_dif_dsc: 0.6971 - val_dif_tp: 0.6568 - val_dif_tn: 0.9802\n",
      "\n",
      "Epoch 00061: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 62/100\n",
      " - 4s - loss: 0.0841 - mask_1_loss: 0.0403 - mask_2_loss: 0.0293 - dif_loss: 0.0964 - mask_1_dsc: 0.9597 - mask_2_dsc: 0.9707 - dif_dsc: 0.9036 - dif_tp: 0.9099 - dif_tn: 0.9909 - val_loss: 0.2578 - val_mask_1_loss: 0.1152 - val_mask_2_loss: 0.0866 - val_dif_loss: 0.2964 - val_mask_1_dsc: 0.8848 - val_mask_2_dsc: 0.9134 - val_dif_dsc: 0.7036 - val_dif_tp: 0.6685 - val_dif_tn: 0.9792\n",
      "\n",
      "Epoch 00062: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 63/100\n",
      " - 4s - loss: 0.0844 - mask_1_loss: 0.0408 - mask_2_loss: 0.0296 - dif_loss: 0.0966 - mask_1_dsc: 0.9592 - mask_2_dsc: 0.9704 - dif_dsc: 0.9034 - dif_tp: 0.9102 - dif_tn: 0.9908 - val_loss: 0.2565 - val_mask_1_loss: 0.1171 - val_mask_2_loss: 0.0866 - val_dif_loss: 0.2949 - val_mask_1_dsc: 0.8829 - val_mask_2_dsc: 0.9134 - val_dif_dsc: 0.7051 - val_dif_tp: 0.6780 - val_dif_tn: 0.9785\n",
      "\n",
      "Epoch 00063: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 64/100\n",
      " - 4s - loss: 0.0823 - mask_1_loss: 0.0396 - mask_2_loss: 0.0292 - dif_loss: 0.0944 - mask_1_dsc: 0.9604 - mask_2_dsc: 0.9708 - dif_dsc: 0.9056 - dif_tp: 0.9132 - dif_tn: 0.9910 - val_loss: 0.2585 - val_mask_1_loss: 0.1146 - val_mask_2_loss: 0.0860 - val_dif_loss: 0.2977 - val_mask_1_dsc: 0.8854 - val_mask_2_dsc: 0.9140 - val_dif_dsc: 0.7023 - val_dif_tp: 0.6578 - val_dif_tn: 0.9812\n",
      "\n",
      "Epoch 00064: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 65/100\n",
      " - 4s - loss: 0.0838 - mask_1_loss: 0.0397 - mask_2_loss: 0.0297 - dif_loss: 0.0962 - mask_1_dsc: 0.9603 - mask_2_dsc: 0.9703 - dif_dsc: 0.9038 - dif_tp: 0.9102 - dif_tn: 0.9909 - val_loss: 0.2509 - val_mask_1_loss: 0.1171 - val_mask_2_loss: 0.0860 - val_dif_loss: 0.2876 - val_mask_1_dsc: 0.8829 - val_mask_2_dsc: 0.9140 - val_dif_dsc: 0.7124 - val_dif_tp: 0.7026 - val_dif_tn: 0.9763\n",
      "\n",
      "Epoch 00065: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 66/100\n",
      " - 4s - loss: 0.0843 - mask_1_loss: 0.0402 - mask_2_loss: 0.0296 - dif_loss: 0.0967 - mask_1_dsc: 0.9598 - mask_2_dsc: 0.9704 - dif_dsc: 0.9033 - dif_tp: 0.9104 - dif_tn: 0.9907 - val_loss: 0.2513 - val_mask_1_loss: 0.1137 - val_mask_2_loss: 0.0853 - val_dif_loss: 0.2878 - val_mask_1_dsc: 0.8863 - val_mask_2_dsc: 0.9147 - val_dif_dsc: 0.7122 - val_dif_tp: 0.6867 - val_dif_tn: 0.9789\n",
      "\n",
      "Epoch 00066: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 67/100\n",
      " - 4s - loss: 0.0867 - mask_1_loss: 0.0416 - mask_2_loss: 0.0299 - dif_loss: 0.0996 - mask_1_dsc: 0.9584 - mask_2_dsc: 0.9701 - dif_dsc: 0.9004 - dif_tp: 0.9077 - dif_tn: 0.9904 - val_loss: 0.2567 - val_mask_1_loss: 0.1170 - val_mask_2_loss: 0.0851 - val_dif_loss: 0.2944 - val_mask_1_dsc: 0.8830 - val_mask_2_dsc: 0.9149 - val_dif_dsc: 0.7056 - val_dif_tp: 0.6672 - val_dif_tn: 0.9802\n",
      "\n",
      "Epoch 00067: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 68/100\n",
      " - 4s - loss: 0.0863 - mask_1_loss: 0.0413 - mask_2_loss: 0.0301 - dif_loss: 0.0990 - mask_1_dsc: 0.9587 - mask_2_dsc: 0.9699 - dif_dsc: 0.9010 - dif_tp: 0.9086 - dif_tn: 0.9904 - val_loss: 0.2543 - val_mask_1_loss: 0.1156 - val_mask_2_loss: 0.0869 - val_dif_loss: 0.2918 - val_mask_1_dsc: 0.8844 - val_mask_2_dsc: 0.9131 - val_dif_dsc: 0.7082 - val_dif_tp: 0.6969 - val_dif_tn: 0.9764\n",
      "\n",
      "Epoch 00068: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 69/100\n",
      " - 4s - loss: 0.0853 - mask_1_loss: 0.0400 - mask_2_loss: 0.0301 - dif_loss: 0.0978 - mask_1_dsc: 0.9600 - mask_2_dsc: 0.9699 - dif_dsc: 0.9022 - dif_tp: 0.9096 - dif_tn: 0.9905 - val_loss: 0.2506 - val_mask_1_loss: 0.1161 - val_mask_2_loss: 0.0853 - val_dif_loss: 0.2870 - val_mask_1_dsc: 0.8839 - val_mask_2_dsc: 0.9147 - val_dif_dsc: 0.7130 - val_dif_tp: 0.6966 - val_dif_tn: 0.9771\n",
      "\n",
      "Epoch 00069: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 70/100\n",
      " - 4s - loss: 0.0829 - mask_1_loss: 0.0395 - mask_2_loss: 0.0293 - dif_loss: 0.0951 - mask_1_dsc: 0.9605 - mask_2_dsc: 0.9707 - dif_dsc: 0.9049 - dif_tp: 0.9119 - dif_tn: 0.9908 - val_loss: 0.2473 - val_mask_1_loss: 0.1165 - val_mask_2_loss: 0.0850 - val_dif_loss: 0.2835 - val_mask_1_dsc: 0.8835 - val_mask_2_dsc: 0.9150 - val_dif_dsc: 0.7165 - val_dif_tp: 0.7176 - val_dif_tn: 0.9744\n",
      "\n",
      "Epoch 00070: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 71/100\n",
      " - 4s - loss: 0.0855 - mask_1_loss: 0.0404 - mask_2_loss: 0.0302 - dif_loss: 0.0982 - mask_1_dsc: 0.9596 - mask_2_dsc: 0.9698 - dif_dsc: 0.9018 - dif_tp: 0.9091 - dif_tn: 0.9906 - val_loss: 0.2562 - val_mask_1_loss: 0.1172 - val_mask_2_loss: 0.0866 - val_dif_loss: 0.2939 - val_mask_1_dsc: 0.8828 - val_mask_2_dsc: 0.9134 - val_dif_dsc: 0.7061 - val_dif_tp: 0.6854 - val_dif_tn: 0.9774\n",
      "\n",
      "Epoch 00071: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 72/100\n",
      " - 4s - loss: 0.0895 - mask_1_loss: 0.0426 - mask_2_loss: 0.0311 - dif_loss: 0.1027 - mask_1_dsc: 0.9574 - mask_2_dsc: 0.9689 - dif_dsc: 0.8973 - dif_tp: 0.9048 - dif_tn: 0.9902 - val_loss: 0.2492 - val_mask_1_loss: 0.1154 - val_mask_2_loss: 0.0868 - val_dif_loss: 0.2865 - val_mask_1_dsc: 0.8846 - val_mask_2_dsc: 0.9132 - val_dif_dsc: 0.7135 - val_dif_tp: 0.7171 - val_dif_tn: 0.9740\n",
      "\n",
      "Epoch 00072: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 73/100\n",
      " - 4s - loss: 0.0913 - mask_1_loss: 0.0432 - mask_2_loss: 0.0318 - dif_loss: 0.1047 - mask_1_dsc: 0.9568 - mask_2_dsc: 0.9682 - dif_dsc: 0.8953 - dif_tp: 0.9033 - dif_tn: 0.9899 - val_loss: 0.2453 - val_mask_1_loss: 0.1158 - val_mask_2_loss: 0.0851 - val_dif_loss: 0.2818 - val_mask_1_dsc: 0.8842 - val_mask_2_dsc: 0.9149 - val_dif_dsc: 0.7182 - val_dif_tp: 0.7231 - val_dif_tn: 0.9741\n",
      "\n",
      "Epoch 00073: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 4s - loss: 0.0895 - mask_1_loss: 0.0423 - mask_2_loss: 0.0311 - dif_loss: 0.1029 - mask_1_dsc: 0.9577 - mask_2_dsc: 0.9689 - dif_dsc: 0.8971 - dif_tp: 0.9045 - dif_tn: 0.9903 - val_loss: 0.2525 - val_mask_1_loss: 0.1174 - val_mask_2_loss: 0.0875 - val_dif_loss: 0.2907 - val_mask_1_dsc: 0.8826 - val_mask_2_dsc: 0.9125 - val_dif_dsc: 0.7093 - val_dif_tp: 0.7076 - val_dif_tn: 0.9745\n",
      "\n",
      "Epoch 00074: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 75/100\n",
      " - 4s - loss: 0.0849 - mask_1_loss: 0.0401 - mask_2_loss: 0.0298 - dif_loss: 0.0974 - mask_1_dsc: 0.9599 - mask_2_dsc: 0.9702 - dif_dsc: 0.9026 - dif_tp: 0.9092 - dif_tn: 0.9907 - val_loss: 0.2564 - val_mask_1_loss: 0.1194 - val_mask_2_loss: 0.0879 - val_dif_loss: 0.2968 - val_mask_1_dsc: 0.8806 - val_mask_2_dsc: 0.9121 - val_dif_dsc: 0.7032 - val_dif_tp: 0.6842 - val_dif_tn: 0.9773\n",
      "\n",
      "Epoch 00075: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 76/100\n",
      " - 4s - loss: 0.0861 - mask_1_loss: 0.0406 - mask_2_loss: 0.0302 - dif_loss: 0.0989 - mask_1_dsc: 0.9594 - mask_2_dsc: 0.9698 - dif_dsc: 0.9011 - dif_tp: 0.9085 - dif_tn: 0.9904 - val_loss: 0.2574 - val_mask_1_loss: 0.1181 - val_mask_2_loss: 0.0870 - val_dif_loss: 0.2962 - val_mask_1_dsc: 0.8819 - val_mask_2_dsc: 0.9130 - val_dif_dsc: 0.7038 - val_dif_tp: 0.6743 - val_dif_tn: 0.9790\n",
      "\n",
      "Epoch 00076: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 77/100\n",
      " - 4s - loss: 0.0870 - mask_1_loss: 0.0408 - mask_2_loss: 0.0300 - dif_loss: 0.1000 - mask_1_dsc: 0.9592 - mask_2_dsc: 0.9700 - dif_dsc: 0.9000 - dif_tp: 0.9081 - dif_tn: 0.9904 - val_loss: 0.2587 - val_mask_1_loss: 0.1158 - val_mask_2_loss: 0.0866 - val_dif_loss: 0.2967 - val_mask_1_dsc: 0.8842 - val_mask_2_dsc: 0.9134 - val_dif_dsc: 0.7033 - val_dif_tp: 0.6724 - val_dif_tn: 0.9789\n",
      "\n",
      "Epoch 00077: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 78/100\n",
      " - 4s - loss: 0.0870 - mask_1_loss: 0.0406 - mask_2_loss: 0.0305 - dif_loss: 0.0998 - mask_1_dsc: 0.9594 - mask_2_dsc: 0.9695 - dif_dsc: 0.9002 - dif_tp: 0.9067 - dif_tn: 0.9905 - val_loss: 0.2535 - val_mask_1_loss: 0.1142 - val_mask_2_loss: 0.0870 - val_dif_loss: 0.2909 - val_mask_1_dsc: 0.8858 - val_mask_2_dsc: 0.9130 - val_dif_dsc: 0.7091 - val_dif_tp: 0.6901 - val_dif_tn: 0.9770\n",
      "\n",
      "Epoch 00078: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 79/100\n",
      " - 4s - loss: 0.0842 - mask_1_loss: 0.0403 - mask_2_loss: 0.0293 - dif_loss: 0.0966 - mask_1_dsc: 0.9597 - mask_2_dsc: 0.9707 - dif_dsc: 0.9034 - dif_tp: 0.9100 - dif_tn: 0.9908 - val_loss: 0.2488 - val_mask_1_loss: 0.1141 - val_mask_2_loss: 0.0846 - val_dif_loss: 0.2855 - val_mask_1_dsc: 0.8859 - val_mask_2_dsc: 0.9154 - val_dif_dsc: 0.7145 - val_dif_tp: 0.6975 - val_dif_tn: 0.9770\n",
      "\n",
      "Epoch 00079: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 80/100\n",
      " - 4s - loss: 0.0829 - mask_1_loss: 0.0384 - mask_2_loss: 0.0293 - dif_loss: 0.0951 - mask_1_dsc: 0.9616 - mask_2_dsc: 0.9707 - dif_dsc: 0.9049 - dif_tp: 0.9110 - dif_tn: 0.9911 - val_loss: 0.2541 - val_mask_1_loss: 0.1140 - val_mask_2_loss: 0.0851 - val_dif_loss: 0.2917 - val_mask_1_dsc: 0.8860 - val_mask_2_dsc: 0.9149 - val_dif_dsc: 0.7083 - val_dif_tp: 0.6780 - val_dif_tn: 0.9789\n",
      "\n",
      "Epoch 00080: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 81/100\n",
      " - 4s - loss: 0.0779 - mask_1_loss: 0.0368 - mask_2_loss: 0.0274 - dif_loss: 0.0893 - mask_1_dsc: 0.9632 - mask_2_dsc: 0.9726 - dif_dsc: 0.9107 - dif_tp: 0.9166 - dif_tn: 0.9914 - val_loss: 0.2591 - val_mask_1_loss: 0.1162 - val_mask_2_loss: 0.0864 - val_dif_loss: 0.2971 - val_mask_1_dsc: 0.8838 - val_mask_2_dsc: 0.9136 - val_dif_dsc: 0.7029 - val_dif_tp: 0.6697 - val_dif_tn: 0.9793\n",
      "\n",
      "Epoch 00081: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 82/100\n",
      " - 4s - loss: 0.0779 - mask_1_loss: 0.0370 - mask_2_loss: 0.0277 - dif_loss: 0.0892 - mask_1_dsc: 0.9630 - mask_2_dsc: 0.9723 - dif_dsc: 0.9108 - dif_tp: 0.9159 - dif_tn: 0.9916 - val_loss: 0.2624 - val_mask_1_loss: 0.1148 - val_mask_2_loss: 0.0892 - val_dif_loss: 0.3016 - val_mask_1_dsc: 0.8852 - val_mask_2_dsc: 0.9108 - val_dif_dsc: 0.6984 - val_dif_tp: 0.6624 - val_dif_tn: 0.9795\n",
      "\n",
      "Epoch 00082: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 83/100\n",
      " - 4s - loss: 0.0757 - mask_1_loss: 0.0359 - mask_2_loss: 0.0270 - dif_loss: 0.0868 - mask_1_dsc: 0.9641 - mask_2_dsc: 0.9730 - dif_dsc: 0.9132 - dif_tp: 0.9183 - dif_tn: 0.9918 - val_loss: 0.2555 - val_mask_1_loss: 0.1186 - val_mask_2_loss: 0.0869 - val_dif_loss: 0.2938 - val_mask_1_dsc: 0.8814 - val_mask_2_dsc: 0.9131 - val_dif_dsc: 0.7062 - val_dif_tp: 0.6843 - val_dif_tn: 0.9777\n",
      "\n",
      "Epoch 00083: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 84/100\n",
      " - 4s - loss: 0.0736 - mask_1_loss: 0.0349 - mask_2_loss: 0.0262 - dif_loss: 0.0843 - mask_1_dsc: 0.9651 - mask_2_dsc: 0.9738 - dif_dsc: 0.9157 - dif_tp: 0.9200 - dif_tn: 0.9920 - val_loss: 0.2586 - val_mask_1_loss: 0.1160 - val_mask_2_loss: 0.0867 - val_dif_loss: 0.2966 - val_mask_1_dsc: 0.8840 - val_mask_2_dsc: 0.9133 - val_dif_dsc: 0.7034 - val_dif_tp: 0.6709 - val_dif_tn: 0.9795\n",
      "\n",
      "Epoch 00084: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 85/100\n",
      " - 4s - loss: 0.0727 - mask_1_loss: 0.0347 - mask_2_loss: 0.0262 - dif_loss: 0.0834 - mask_1_dsc: 0.9653 - mask_2_dsc: 0.9738 - dif_dsc: 0.9166 - dif_tp: 0.9217 - dif_tn: 0.9921 - val_loss: 0.2549 - val_mask_1_loss: 0.1157 - val_mask_2_loss: 0.0868 - val_dif_loss: 0.2932 - val_mask_1_dsc: 0.8843 - val_mask_2_dsc: 0.9132 - val_dif_dsc: 0.7068 - val_dif_tp: 0.6841 - val_dif_tn: 0.9778\n",
      "\n",
      "Epoch 00085: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 86/100\n",
      " - 4s - loss: 0.0718 - mask_1_loss: 0.0335 - mask_2_loss: 0.0258 - dif_loss: 0.0823 - mask_1_dsc: 0.9665 - mask_2_dsc: 0.9742 - dif_dsc: 0.9177 - dif_tp: 0.9218 - dif_tn: 0.9923 - val_loss: 0.2591 - val_mask_1_loss: 0.1147 - val_mask_2_loss: 0.0869 - val_dif_loss: 0.2974 - val_mask_1_dsc: 0.8853 - val_mask_2_dsc: 0.9131 - val_dif_dsc: 0.7026 - val_dif_tp: 0.6645 - val_dif_tn: 0.9798\n",
      "\n",
      "Epoch 00086: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 87/100\n",
      " - 4s - loss: 0.0706 - mask_1_loss: 0.0332 - mask_2_loss: 0.0254 - dif_loss: 0.0807 - mask_1_dsc: 0.9668 - mask_2_dsc: 0.9746 - dif_dsc: 0.9193 - dif_tp: 0.9240 - dif_tn: 0.9924 - val_loss: 0.2541 - val_mask_1_loss: 0.1140 - val_mask_2_loss: 0.0859 - val_dif_loss: 0.2919 - val_mask_1_dsc: 0.8860 - val_mask_2_dsc: 0.9141 - val_dif_dsc: 0.7081 - val_dif_tp: 0.6793 - val_dif_tn: 0.9788\n",
      "\n",
      "Epoch 00087: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 88/100\n",
      " - 4s - loss: 0.0694 - mask_1_loss: 0.0328 - mask_2_loss: 0.0247 - dif_loss: 0.0797 - mask_1_dsc: 0.9672 - mask_2_dsc: 0.9753 - dif_dsc: 0.9203 - dif_tp: 0.9255 - dif_tn: 0.9926 - val_loss: 0.2556 - val_mask_1_loss: 0.1147 - val_mask_2_loss: 0.0859 - val_dif_loss: 0.2935 - val_mask_1_dsc: 0.8853 - val_mask_2_dsc: 0.9141 - val_dif_dsc: 0.7065 - val_dif_tp: 0.6772 - val_dif_tn: 0.9788\n",
      "\n",
      "Epoch 00088: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 89/100\n",
      " - 4s - loss: 0.0679 - mask_1_loss: 0.0321 - mask_2_loss: 0.0245 - dif_loss: 0.0777 - mask_1_dsc: 0.9679 - mask_2_dsc: 0.9755 - dif_dsc: 0.9223 - dif_tp: 0.9267 - dif_tn: 0.9927 - val_loss: 0.2565 - val_mask_1_loss: 0.1150 - val_mask_2_loss: 0.0866 - val_dif_loss: 0.2949 - val_mask_1_dsc: 0.8850 - val_mask_2_dsc: 0.9134 - val_dif_dsc: 0.7051 - val_dif_tp: 0.6715 - val_dif_tn: 0.9795\n",
      "\n",
      "Epoch 00089: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 90/100\n",
      " - 4s - loss: 0.0660 - mask_1_loss: 0.0317 - mask_2_loss: 0.0240 - dif_loss: 0.0756 - mask_1_dsc: 0.9683 - mask_2_dsc: 0.9760 - dif_dsc: 0.9244 - dif_tp: 0.9278 - dif_tn: 0.9929 - val_loss: 0.2556 - val_mask_1_loss: 0.1156 - val_mask_2_loss: 0.0863 - val_dif_loss: 0.2929 - val_mask_1_dsc: 0.8844 - val_mask_2_dsc: 0.9137 - val_dif_dsc: 0.7071 - val_dif_tp: 0.6841 - val_dif_tn: 0.9776\n",
      "\n",
      "Epoch 00090: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 91/100\n",
      " - 4s - loss: 0.0649 - mask_1_loss: 0.0309 - mask_2_loss: 0.0238 - dif_loss: 0.0742 - mask_1_dsc: 0.9691 - mask_2_dsc: 0.9762 - dif_dsc: 0.9258 - dif_tp: 0.9296 - dif_tn: 0.9931 - val_loss: 0.2591 - val_mask_1_loss: 0.1149 - val_mask_2_loss: 0.0862 - val_dif_loss: 0.2973 - val_mask_1_dsc: 0.8851 - val_mask_2_dsc: 0.9138 - val_dif_dsc: 0.7027 - val_dif_tp: 0.6640 - val_dif_tn: 0.9801\n",
      "\n",
      "Epoch 00091: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 92/100\n",
      " - 4s - loss: 0.0651 - mask_1_loss: 0.0306 - mask_2_loss: 0.0238 - dif_loss: 0.0746 - mask_1_dsc: 0.9694 - mask_2_dsc: 0.9762 - dif_dsc: 0.9254 - dif_tp: 0.9289 - dif_tn: 0.9932 - val_loss: 0.2626 - val_mask_1_loss: 0.1151 - val_mask_2_loss: 0.0876 - val_dif_loss: 0.3011 - val_mask_1_dsc: 0.8849 - val_mask_2_dsc: 0.9124 - val_dif_dsc: 0.6989 - val_dif_tp: 0.6542 - val_dif_tn: 0.9809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00092: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 93/100\n",
      " - 4s - loss: 0.0641 - mask_1_loss: 0.0307 - mask_2_loss: 0.0236 - dif_loss: 0.0735 - mask_1_dsc: 0.9693 - mask_2_dsc: 0.9764 - dif_dsc: 0.9265 - dif_tp: 0.9307 - dif_tn: 0.9932 - val_loss: 0.2535 - val_mask_1_loss: 0.1144 - val_mask_2_loss: 0.0865 - val_dif_loss: 0.2912 - val_mask_1_dsc: 0.8856 - val_mask_2_dsc: 0.9135 - val_dif_dsc: 0.7088 - val_dif_tp: 0.6883 - val_dif_tn: 0.9776\n",
      "\n",
      "Epoch 00093: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 94/100\n",
      " - 4s - loss: 0.0625 - mask_1_loss: 0.0297 - mask_2_loss: 0.0229 - dif_loss: 0.0720 - mask_1_dsc: 0.9703 - mask_2_dsc: 0.9771 - dif_dsc: 0.9280 - dif_tp: 0.9313 - dif_tn: 0.9934 - val_loss: 0.2578 - val_mask_1_loss: 0.1149 - val_mask_2_loss: 0.0863 - val_dif_loss: 0.2962 - val_mask_1_dsc: 0.8851 - val_mask_2_dsc: 0.9137 - val_dif_dsc: 0.7038 - val_dif_tp: 0.6724 - val_dif_tn: 0.9788\n",
      "\n",
      "Epoch 00094: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 95/100\n",
      " - 4s - loss: 0.0615 - mask_1_loss: 0.0294 - mask_2_loss: 0.0225 - dif_loss: 0.0704 - mask_1_dsc: 0.9706 - mask_2_dsc: 0.9775 - dif_dsc: 0.9296 - dif_tp: 0.9329 - dif_tn: 0.9935 - val_loss: 0.2562 - val_mask_1_loss: 0.1144 - val_mask_2_loss: 0.0863 - val_dif_loss: 0.2945 - val_mask_1_dsc: 0.8856 - val_mask_2_dsc: 0.9137 - val_dif_dsc: 0.7055 - val_dif_tp: 0.6704 - val_dif_tn: 0.9797\n",
      "\n",
      "Epoch 00095: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 96/100\n",
      " - 4s - loss: 0.0597 - mask_1_loss: 0.0283 - mask_2_loss: 0.0223 - dif_loss: 0.0683 - mask_1_dsc: 0.9717 - mask_2_dsc: 0.9777 - dif_dsc: 0.9317 - dif_tp: 0.9355 - dif_tn: 0.9937 - val_loss: 0.2589 - val_mask_1_loss: 0.1147 - val_mask_2_loss: 0.0863 - val_dif_loss: 0.2971 - val_mask_1_dsc: 0.8853 - val_mask_2_dsc: 0.9137 - val_dif_dsc: 0.7029 - val_dif_tp: 0.6644 - val_dif_tn: 0.9800\n",
      "\n",
      "Epoch 00096: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 97/100\n",
      " - 4s - loss: 0.0593 - mask_1_loss: 0.0280 - mask_2_loss: 0.0220 - dif_loss: 0.0679 - mask_1_dsc: 0.9720 - mask_2_dsc: 0.9780 - dif_dsc: 0.9321 - dif_tp: 0.9347 - dif_tn: 0.9938 - val_loss: 0.2571 - val_mask_1_loss: 0.1161 - val_mask_2_loss: 0.0860 - val_dif_loss: 0.2947 - val_mask_1_dsc: 0.8839 - val_mask_2_dsc: 0.9140 - val_dif_dsc: 0.7053 - val_dif_tp: 0.6776 - val_dif_tn: 0.9784\n",
      "\n",
      "Epoch 00097: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 98/100\n",
      " - 4s - loss: 0.0580 - mask_1_loss: 0.0276 - mask_2_loss: 0.0214 - dif_loss: 0.0663 - mask_1_dsc: 0.9724 - mask_2_dsc: 0.9786 - dif_dsc: 0.9337 - dif_tp: 0.9363 - dif_tn: 0.9939 - val_loss: 0.2549 - val_mask_1_loss: 0.1139 - val_mask_2_loss: 0.0859 - val_dif_loss: 0.2925 - val_mask_1_dsc: 0.8861 - val_mask_2_dsc: 0.9141 - val_dif_dsc: 0.7075 - val_dif_tp: 0.6753 - val_dif_tn: 0.9793\n",
      "\n",
      "Epoch 00098: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 99/100\n",
      " - 4s - loss: 0.0564 - mask_1_loss: 0.0271 - mask_2_loss: 0.0210 - dif_loss: 0.0645 - mask_1_dsc: 0.9729 - mask_2_dsc: 0.9790 - dif_dsc: 0.9355 - dif_tp: 0.9390 - dif_tn: 0.9940 - val_loss: 0.2581 - val_mask_1_loss: 0.1153 - val_mask_2_loss: 0.0864 - val_dif_loss: 0.2962 - val_mask_1_dsc: 0.8847 - val_mask_2_dsc: 0.9136 - val_dif_dsc: 0.7038 - val_dif_tp: 0.6676 - val_dif_tn: 0.9798\n",
      "\n",
      "Epoch 00099: val_dif_dsc did not improve from 0.72723\n",
      "Epoch 100/100\n",
      " - 4s - loss: 0.0557 - mask_1_loss: 0.0269 - mask_2_loss: 0.0209 - dif_loss: 0.0637 - mask_1_dsc: 0.9731 - mask_2_dsc: 0.9791 - dif_dsc: 0.9363 - dif_tp: 0.9386 - dif_tn: 0.9942 - val_loss: 0.2571 - val_mask_1_loss: 0.1147 - val_mask_2_loss: 0.0862 - val_dif_loss: 0.2951 - val_mask_1_dsc: 0.8853 - val_mask_2_dsc: 0.9138 - val_dif_dsc: 0.7049 - val_dif_tp: 0.6714 - val_dif_tn: 0.9794\n",
      "\n",
      "Epoch 00100: val_dif_dsc did not improve from 0.72723\n"
     ]
    }
   ],
   "source": [
    "epoch_number = 100\n",
    "batch_number = 8\n",
    "model_checkpoint=model_logs+'cyclic_attn_unet_3D_plaque_epoch_{epoch:03d}_valdsc_{val_dif_dsc:03f}.h5'\n",
    "checkpoint = ModelCheckpoint(model_checkpoint,\n",
    "                             verbose=1,\n",
    "                             monitor='val_dif_dsc',\n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "LR=args.learning_rate\n",
    "cyclic_lr = CyclicLR(base_lr=LR, max_lr=LR*6, step_size=2000.0)\n",
    "history_attn_unet = model.fit(train_images/512,\n",
    "                                        [train_masks_1, train_masks_2, train_dif],\n",
    "                                        epochs = epoch_number,\n",
    "                                        batch_size=batch_number,\n",
    "                                        verbose=2,\n",
    "                                        shuffle=True,\n",
    "                                        validation_data=(val_images/512, [val_masks_1, val_masks_2, val_dif]),\n",
    "                                        callbacks=[checkpoint,cyclic_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tiny_attn_unet3D(Adam(learning_rate=args.learning_rate), (24,32,32,1),args)\n",
    "#model.load_weights('') #can load the created best model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_automata_vs_prediction_nf(image_array, diff_array, aut_array, pred_array, opacity=0.8, name = \"\",strictness=9,Two_Dim=True):\n",
    "    ax, plots = plt.subplots(2, 3, figsize=(25, 10))\n",
    "    ax.suptitle(name)\n",
    "    plots[0,0].axis('off')\n",
    "    plots[0,0].imshow(diff_array, cmap=plt.cm.bone)\n",
    "    plots[0,0].set_title('Doctor')\n",
    "    plots[0,1].axis('off')\n",
    "    plots[0,1].imshow(aut_array, cmap=plt.cm.bone)\n",
    "    plots[0,1].set_title('Automata')\n",
    "    plots[0,2].axis('off')\n",
    "    plots[0,2].imshow(pred_array, cmap=plt.cm.bone)\n",
    "    plots[0,2].set_title('ML')\n",
    "    \n",
    "    plots[1,0].axis('off')\n",
    "    plots[1,0].imshow(superimpose_mask2(image_array, diff_array, opacity=opacity))\n",
    "    plots[1,1].axis('off')\n",
    "    plots[1,1].imshow(superimpose_mask2(image_array, aut_array, opacity=opacity))\n",
    "    plots[1,2].axis('off')\n",
    "    plots[1,2].imshow(superimpose_mask2(image_array, pred_array, opacity=opacity))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vessel(image_name,L):    \n",
    "    '''\n",
    "    image_name is is the name of the image to be visualized\n",
    "    L is the slice of the image which is to be visualized\n",
    "    '''\n",
    "    image_path = os.path.join(basic_path, image_name)\n",
    "\n",
    "    image_dicom=pydicom.dcmread(image_path)\n",
    "    images = image_dicom.pixel_array \n",
    "\n",
    "    mask_1_path = os.path.join(basic_path, image_name[:-13]+\"Contour1.dcm\")\n",
    "    mask_2_path = os.path.join(basic_path, image_name[:-13]+\"Contour2.dcm\")\n",
    "\n",
    "    mask_1=mask_from_dicom(mask_1_path)\n",
    "    mask_1cut=np.zeros(mask_1.shape).astype('int')\n",
    "    mask_1cut[:,16:48,16:48]=mask_1[:,16:48,16:48]\n",
    "\n",
    "    mask_2=mask_from_dicom(mask_2_path)\n",
    "    mask_2cut=np.zeros(mask_2.shape).astype('int')\n",
    "    mask_2cut[:,16:48,16:48]=mask_2[:,16:48,16:48]\n",
    "\n",
    "    masks[0,1,j] = mask_1cut\n",
    "    masks[0,2,j] = mask_2cut\n",
    "    masks[0,0,j] = masks[0,2,j]-masks[0,1,j]                    \n",
    "        \n",
    "    masks[0,0,j+1] = full_ct_model_evaluation(image = images, model = model, z_stride = 12, which_prediction=2)\n",
    "    masks[0,1,j+1] = full_ct_model_evaluation(image = images, model = model, z_stride = 12, which_prediction=0)\n",
    "    masks[0,2,j+1] = full_ct_model_evaluation(image = images, model = model, z_stride = 12, which_prediction=1)  \n",
    "\n",
    "    visualize_automata_vs_prediction_nf(images[L],masks[0,0,1][L],masks[0,0,0][L],masks[0,0,2][L])\n",
    "     \n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>trainvaltest</th>\n",
       "      <th>volumeAUTOMATA</th>\n",
       "      <th>volumeAUTOMATA-DenseCalcium</th>\n",
       "      <th>volumeAUTOMATA-Fibrous</th>\n",
       "      <th>volumeAUTOMATA-FibrousFatty</th>\n",
       "      <th>volumeAUTOMATA-NecroticCore</th>\n",
       "      <th>volumeAUTOMATA-NonCalcified</th>\n",
       "      <th>inner_dsc-AUTOMATA-AUTOMATA</th>\n",
       "      <th>inner_dsc-AUTOMATA-KM</th>\n",
       "      <th>inner_dsc-AUTOMATA-Prediciton</th>\n",
       "      <th>outer_dsc-AUTOMATA-AUTOMATA</th>\n",
       "      <th>outer_dsc-AUTOMATA-KM</th>\n",
       "      <th>outer_dsc-AUTOMATA-Prediciton</th>\n",
       "      <th>mask_dsc-AUTOMATA-AUTOMATA</th>\n",
       "      <th>mask_dsc-AUTOMATA-KM</th>\n",
       "      <th>mask_dsc-AUTOMATA-Prediciton</th>\n",
       "      <th>volumeKM</th>\n",
       "      <th>volumeKM-DenseCalcium</th>\n",
       "      <th>volumeKM-Fibrous</th>\n",
       "      <th>volumeKM-FibrousFatty</th>\n",
       "      <th>volumeKM-NecroticCore</th>\n",
       "      <th>volumeKM-NonCalcified</th>\n",
       "      <th>inner_dsc-KM-AUTOMATA</th>\n",
       "      <th>inner_dsc-KM-KM</th>\n",
       "      <th>inner_dsc-KM-Prediciton</th>\n",
       "      <th>outer_dsc-KM-AUTOMATA</th>\n",
       "      <th>outer_dsc-KM-KM</th>\n",
       "      <th>outer_dsc-KM-Prediciton</th>\n",
       "      <th>mask_dsc-KM-AUTOMATA</th>\n",
       "      <th>mask_dsc-KM-KM</th>\n",
       "      <th>mask_dsc-KM-Prediciton</th>\n",
       "      <th>volumePrediciton</th>\n",
       "      <th>volumePrediciton-DenseCalcium</th>\n",
       "      <th>volumePrediciton-Fibrous</th>\n",
       "      <th>volumePrediciton-FibrousFatty</th>\n",
       "      <th>volumePrediciton-NecroticCore</th>\n",
       "      <th>volumePrediciton-NonCalcified</th>\n",
       "      <th>inner_dsc-Prediciton-AUTOMATA</th>\n",
       "      <th>inner_dsc-Prediciton-KM</th>\n",
       "      <th>inner_dsc-Prediciton-Prediciton</th>\n",
       "      <th>outer_dsc-Prediciton-AUTOMATA</th>\n",
       "      <th>outer_dsc-Prediciton-KM</th>\n",
       "      <th>outer_dsc-Prediciton-Prediciton</th>\n",
       "      <th>mask_dsc-Prediciton-AUTOMATA</th>\n",
       "      <th>mask_dsc-Prediciton-KM</th>\n",
       "      <th>mask_dsc-Prediciton-Prediciton</th>\n",
       "      <th>volumeAUTOMATA_filter</th>\n",
       "      <th>volumeAUTOMATA_filter-DenseCalcium</th>\n",
       "      <th>volumeAUTOMATA_filter-Fibrous</th>\n",
       "      <th>volumeAUTOMATA_filter-FibrousFatty</th>\n",
       "      <th>volumeAUTOMATA_filter-NecroticCore</th>\n",
       "      <th>volumeAUTOMATA_filter-NonCalcified</th>\n",
       "      <th>inner_dsc_filter-AUTOMATA-AUTOMATA</th>\n",
       "      <th>inner_dsc_filter-AUTOMATA-KM</th>\n",
       "      <th>inner_dsc_filter-AUTOMATA-Prediciton</th>\n",
       "      <th>outer_dsc_filter-AUTOMATA-AUTOMATA</th>\n",
       "      <th>outer_dsc_filter-AUTOMATA-KM</th>\n",
       "      <th>outer_dsc_filter-AUTOMATA-Prediciton</th>\n",
       "      <th>mask_dsc_filter-AUTOMATA-AUTOMATA</th>\n",
       "      <th>mask_dsc_filter-AUTOMATA-KM</th>\n",
       "      <th>mask_dsc_filter-AUTOMATA-Prediciton</th>\n",
       "      <th>volumeKM_filter</th>\n",
       "      <th>volumeKM_filter-DenseCalcium</th>\n",
       "      <th>volumeKM_filter-Fibrous</th>\n",
       "      <th>volumeKM_filter-FibrousFatty</th>\n",
       "      <th>volumeKM_filter-NecroticCore</th>\n",
       "      <th>volumeKM_filter-NonCalcified</th>\n",
       "      <th>inner_dsc_filter-KM-AUTOMATA</th>\n",
       "      <th>inner_dsc_filter-KM-KM</th>\n",
       "      <th>inner_dsc_filter-KM-Prediciton</th>\n",
       "      <th>outer_dsc_filter-KM-AUTOMATA</th>\n",
       "      <th>outer_dsc_filter-KM-KM</th>\n",
       "      <th>outer_dsc_filter-KM-Prediciton</th>\n",
       "      <th>mask_dsc_filter-KM-AUTOMATA</th>\n",
       "      <th>mask_dsc_filter-KM-KM</th>\n",
       "      <th>mask_dsc_filter-KM-Prediciton</th>\n",
       "      <th>volumePrediciton_filter</th>\n",
       "      <th>volumePrediciton_filter-DenseCalcium</th>\n",
       "      <th>volumePrediciton_filter-Fibrous</th>\n",
       "      <th>volumePrediciton_filter-FibrousFatty</th>\n",
       "      <th>volumePrediciton_filter-NecroticCore</th>\n",
       "      <th>volumePrediciton_filter-NonCalcified</th>\n",
       "      <th>inner_dsc_filter-Prediciton-AUTOMATA</th>\n",
       "      <th>inner_dsc_filter-Prediciton-KM</th>\n",
       "      <th>inner_dsc_filter-Prediciton-Prediciton</th>\n",
       "      <th>outer_dsc_filter-Prediciton-AUTOMATA</th>\n",
       "      <th>outer_dsc_filter-Prediciton-KM</th>\n",
       "      <th>outer_dsc_filter-Prediciton-Prediciton</th>\n",
       "      <th>mask_dsc_filter-Prediciton-AUTOMATA</th>\n",
       "      <th>mask_dsc_filter-Prediciton-KM</th>\n",
       "      <th>mask_dsc_filter-Prediciton-Prediciton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PA00002</td>\n",
       "      <td>test</td>\n",
       "      <td>147.875</td>\n",
       "      <td>12.5</td>\n",
       "      <td>113.90625</td>\n",
       "      <td>13.9375</td>\n",
       "      <td>6.15625</td>\n",
       "      <td>135.03125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974962</td>\n",
       "      <td>0.903763</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.792271</td>\n",
       "      <td>0.865214</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.484896</td>\n",
       "      <td>0.495719</td>\n",
       "      <td>411.78125</td>\n",
       "      <td>16.625</td>\n",
       "      <td>158.34375</td>\n",
       "      <td>55.75</td>\n",
       "      <td>153.875</td>\n",
       "      <td>394.71875</td>\n",
       "      <td>0.974962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.906309</td>\n",
       "      <td>0.792271</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.856382</td>\n",
       "      <td>0.484896</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.640246</td>\n",
       "      <td>330.21875</td>\n",
       "      <td>24.5625</td>\n",
       "      <td>179.71875</td>\n",
       "      <td>36.5</td>\n",
       "      <td>82.3125</td>\n",
       "      <td>305.25</td>\n",
       "      <td>0.903763</td>\n",
       "      <td>0.906309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.865214</td>\n",
       "      <td>0.856382</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.495719</td>\n",
       "      <td>0.640246</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.625</td>\n",
       "      <td>2.15625</td>\n",
       "      <td>12.15625</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.40625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973877</td>\n",
       "      <td>0.90455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.785098</td>\n",
       "      <td>0.864134</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.075531</td>\n",
       "      <td>0.114613</td>\n",
       "      <td>303.125</td>\n",
       "      <td>9.8125</td>\n",
       "      <td>76.78125</td>\n",
       "      <td>43.15625</td>\n",
       "      <td>147.9375</td>\n",
       "      <td>293.0625</td>\n",
       "      <td>0.973877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.907257</td>\n",
       "      <td>0.785098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.850763</td>\n",
       "      <td>0.075531</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.52613</td>\n",
       "      <td>192.59375</td>\n",
       "      <td>15.75</td>\n",
       "      <td>79.375</td>\n",
       "      <td>20.4375</td>\n",
       "      <td>71.46875</td>\n",
       "      <td>176.53125</td>\n",
       "      <td>0.90455</td>\n",
       "      <td>0.907257</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864134</td>\n",
       "      <td>0.850763</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.114613</td>\n",
       "      <td>0.52613</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient trainvaltest  volumeAUTOMATA  volumeAUTOMATA-DenseCalcium  \\\n",
       "0  PA00002         test         147.875                         12.5   \n",
       "\n",
       "   volumeAUTOMATA-Fibrous  volumeAUTOMATA-FibrousFatty  \\\n",
       "0               113.90625                      13.9375   \n",
       "\n",
       "   volumeAUTOMATA-NecroticCore  volumeAUTOMATA-NonCalcified  \\\n",
       "0                      6.15625                    135.03125   \n",
       "\n",
       "   inner_dsc-AUTOMATA-AUTOMATA  inner_dsc-AUTOMATA-KM  \\\n",
       "0                          1.0               0.974962   \n",
       "\n",
       "   inner_dsc-AUTOMATA-Prediciton  outer_dsc-AUTOMATA-AUTOMATA  \\\n",
       "0                       0.903763                          1.0   \n",
       "\n",
       "   outer_dsc-AUTOMATA-KM  outer_dsc-AUTOMATA-Prediciton  \\\n",
       "0               0.792271                       0.865214   \n",
       "\n",
       "   mask_dsc-AUTOMATA-AUTOMATA  mask_dsc-AUTOMATA-KM  \\\n",
       "0                         1.0              0.484896   \n",
       "\n",
       "   mask_dsc-AUTOMATA-Prediciton   volumeKM  volumeKM-DenseCalcium  \\\n",
       "0                      0.495719  411.78125                 16.625   \n",
       "\n",
       "   volumeKM-Fibrous  volumeKM-FibrousFatty  volumeKM-NecroticCore  \\\n",
       "0         158.34375                  55.75                153.875   \n",
       "\n",
       "   volumeKM-NonCalcified  inner_dsc-KM-AUTOMATA  inner_dsc-KM-KM  \\\n",
       "0              394.71875               0.974962              1.0   \n",
       "\n",
       "   inner_dsc-KM-Prediciton  outer_dsc-KM-AUTOMATA  outer_dsc-KM-KM  \\\n",
       "0                 0.906309               0.792271              1.0   \n",
       "\n",
       "   outer_dsc-KM-Prediciton  mask_dsc-KM-AUTOMATA  mask_dsc-KM-KM  \\\n",
       "0                 0.856382              0.484896             1.0   \n",
       "\n",
       "   mask_dsc-KM-Prediciton  volumePrediciton  volumePrediciton-DenseCalcium  \\\n",
       "0                0.640246         330.21875                        24.5625   \n",
       "\n",
       "   volumePrediciton-Fibrous  volumePrediciton-FibrousFatty  \\\n",
       "0                 179.71875                           36.5   \n",
       "\n",
       "   volumePrediciton-NecroticCore  volumePrediciton-NonCalcified  \\\n",
       "0                        82.3125                         305.25   \n",
       "\n",
       "   inner_dsc-Prediciton-AUTOMATA  inner_dsc-Prediciton-KM  \\\n",
       "0                       0.903763                 0.906309   \n",
       "\n",
       "   inner_dsc-Prediciton-Prediciton  outer_dsc-Prediciton-AUTOMATA  \\\n",
       "0                              1.0                       0.865214   \n",
       "\n",
       "   outer_dsc-Prediciton-KM  outer_dsc-Prediciton-Prediciton  \\\n",
       "0                 0.856382                              1.0   \n",
       "\n",
       "   mask_dsc-Prediciton-AUTOMATA  mask_dsc-Prediciton-KM  \\\n",
       "0                      0.495719                0.640246   \n",
       "\n",
       "   mask_dsc-Prediciton-Prediciton  volumeAUTOMATA_filter  \\\n",
       "0                             1.0                 14.625   \n",
       "\n",
       "   volumeAUTOMATA_filter-DenseCalcium  volumeAUTOMATA_filter-Fibrous  \\\n",
       "0                             2.15625                       12.15625   \n",
       "\n",
       "   volumeAUTOMATA_filter-FibrousFatty  volumeAUTOMATA_filter-NecroticCore  \\\n",
       "0                                0.25                                 0.0   \n",
       "\n",
       "   volumeAUTOMATA_filter-NonCalcified  inner_dsc_filter-AUTOMATA-AUTOMATA  \\\n",
       "0                            12.40625                                 1.0   \n",
       "\n",
       "   inner_dsc_filter-AUTOMATA-KM  inner_dsc_filter-AUTOMATA-Prediciton  \\\n",
       "0                      0.973877                               0.90455   \n",
       "\n",
       "   outer_dsc_filter-AUTOMATA-AUTOMATA  outer_dsc_filter-AUTOMATA-KM  \\\n",
       "0                                 1.0                      0.785098   \n",
       "\n",
       "   outer_dsc_filter-AUTOMATA-Prediciton  mask_dsc_filter-AUTOMATA-AUTOMATA  \\\n",
       "0                              0.864134                                1.0   \n",
       "\n",
       "   mask_dsc_filter-AUTOMATA-KM  mask_dsc_filter-AUTOMATA-Prediciton  \\\n",
       "0                     0.075531                             0.114613   \n",
       "\n",
       "   volumeKM_filter  volumeKM_filter-DenseCalcium  volumeKM_filter-Fibrous  \\\n",
       "0          303.125                        9.8125                 76.78125   \n",
       "\n",
       "   volumeKM_filter-FibrousFatty  volumeKM_filter-NecroticCore  \\\n",
       "0                      43.15625                      147.9375   \n",
       "\n",
       "   volumeKM_filter-NonCalcified  inner_dsc_filter-KM-AUTOMATA  \\\n",
       "0                      293.0625                      0.973877   \n",
       "\n",
       "   inner_dsc_filter-KM-KM  inner_dsc_filter-KM-Prediciton  \\\n",
       "0                     1.0                        0.907257   \n",
       "\n",
       "   outer_dsc_filter-KM-AUTOMATA  outer_dsc_filter-KM-KM  \\\n",
       "0                      0.785098                     1.0   \n",
       "\n",
       "   outer_dsc_filter-KM-Prediciton  mask_dsc_filter-KM-AUTOMATA  \\\n",
       "0                        0.850763                     0.075531   \n",
       "\n",
       "   mask_dsc_filter-KM-KM  mask_dsc_filter-KM-Prediciton  \\\n",
       "0                    1.0                        0.52613   \n",
       "\n",
       "   volumePrediciton_filter  volumePrediciton_filter-DenseCalcium  \\\n",
       "0                192.59375                                 15.75   \n",
       "\n",
       "   volumePrediciton_filter-Fibrous  volumePrediciton_filter-FibrousFatty  \\\n",
       "0                           79.375                               20.4375   \n",
       "\n",
       "   volumePrediciton_filter-NecroticCore  volumePrediciton_filter-NonCalcified  \\\n",
       "0                              71.46875                             176.53125   \n",
       "\n",
       "   inner_dsc_filter-Prediciton-AUTOMATA  inner_dsc_filter-Prediciton-KM  \\\n",
       "0                               0.90455                        0.907257   \n",
       "\n",
       "   inner_dsc_filter-Prediciton-Prediciton  \\\n",
       "0                                     1.0   \n",
       "\n",
       "   outer_dsc_filter-Prediciton-AUTOMATA  outer_dsc_filter-Prediciton-KM  \\\n",
       "0                              0.864134                        0.850763   \n",
       "\n",
       "   outer_dsc_filter-Prediciton-Prediciton  \\\n",
       "0                                     1.0   \n",
       "\n",
       "   mask_dsc_filter-Prediciton-AUTOMATA  mask_dsc_filter-Prediciton-KM  \\\n",
       "0                             0.114613                        0.52613   \n",
       "\n",
       "   mask_dsc_filter-Prediciton-Prediciton  \n",
       "0                                    1.0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_vessel(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
